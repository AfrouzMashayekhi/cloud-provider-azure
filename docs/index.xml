<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cloud Provider Azure – Documentation</title><link>https://nilo19.github.io/cloud-provider-azure/docs/</link><description>Recent content in Documentation on Cloud Provider Azure</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://nilo19.github.io/cloud-provider-azure/docs/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Cloud controller manager for Azure</title><link>https://nilo19.github.io/cloud-provider-azure/docs/ccm/cloud-controller-manager/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/docs/ccm/cloud-controller-manager/</guid><description>
&lt;p>&lt;code>azure-cloud-controller-manager&lt;/code> is a Kubernetes component that provides interoperability with Azure API, and will be used by Kubernetes clusters running on Azure. It runs together with other components to provide the Kubernetes cluster’s control plane.&lt;/p>
&lt;p>Using &lt;a href="https://kubernetes.io/docs/concepts/overview/components/#cloud-controller-manager">cloud-controller-manager&lt;/a> is a new alpha feature for Kubernetes since v1.14. &lt;code>cloud-controller-manager&lt;/code> runs cloud provider related controller loops, which used to be run by &lt;code>controller-manager&lt;/code>.&lt;/p>
&lt;p>&lt;code>azure-cloud-controller-manager&lt;/code> is a specialization of &lt;code>cloud-controller-manager&lt;/code>. It depends on &lt;a href="https://github.com/kubernetes/kubernetes/tree/master/cmd/cloud-controller-manager/app">cloud-controller-manager app&lt;/a> and &lt;a href="https://github.com/kubernetes/kubernetes/tree/master/staging/src/k8s.io/legacy-cloud-providers/azure">azure cloud provider&lt;/a>.&lt;/p>
&lt;h2 id="usage">Usage&lt;/h2>
&lt;p>To use cloud controller manager, the following components need to be configured:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>kubelet&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Flag&lt;/th>
&lt;th>Value&lt;/th>
&lt;th>Remark&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&amp;ndash;cloud-provider&lt;/td>
&lt;td>external&lt;/td>
&lt;td>cloud-provider should be set external&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&amp;ndash;azure-container-registry-config&lt;/td>
&lt;td>/etc/kubernetes/azure.json&lt;/td>
&lt;td>Used for Azure credential provider&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>
&lt;p>kube-controller-manager&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Flag&lt;/th>
&lt;th>Value&lt;/th>
&lt;th>Remark&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&amp;ndash;cloud-provider&lt;/td>
&lt;td>external&lt;/td>
&lt;td>cloud-provider should be set external&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&amp;ndash;external-cloud-volume-plugin&lt;/td>
&lt;td>azure&lt;/td>
&lt;td>Optional*&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;code>*&lt;/code> Since cloud controller manager does not support volume controllers, it will not provide volume capabilities compared to using previous built-in cloud provider case. You can add this flag to turn on volume controller for in-tree cloud providers. This option is likely to be &lt;a href="https://github.com/kubernetes/kubernetes/blob/v1.11.0-alpha.2/cmd/kube-controller-manager/app/options/options.go#L93">removed with in-tree cloud providers&lt;/a> in future.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>kube-apiserver&lt;/p>
&lt;p>Do not set flag &lt;code>--cloud-provider&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>azure-cloud-controller-manager&lt;/p>
&lt;p>Set following flags:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Flag&lt;/th>
&lt;th>Value&lt;/th>
&lt;th>Remark&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&amp;ndash;cloud-provider&lt;/td>
&lt;td>azure&lt;/td>
&lt;td>cloud-provider should be set azure&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&amp;ndash;cloud-config&lt;/td>
&lt;td>/etc/kubernetes/azure.json&lt;/td>
&lt;td>Path for &lt;a href="../config">cloud provider config&lt;/a>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>For other flags such as &lt;code>--allocate-node-cidrs&lt;/code>, &lt;code>--configure-cloud-routes&lt;/code>, &lt;code>--cluster-cidr&lt;/code>, they are moved from kube-controller-manager. If you are migrating from kube-controller-manager, they should be set to same value.&lt;/p>
&lt;p>For details of those flags, please refer to this &lt;a href="https://kubernetes.io/docs/reference/command-line-tools-reference/cloud-controller-manager/">doc&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Alternatively, you can use &lt;a href="https://github.com/Azure/aks-engine">aks-engine&lt;/a> to deploy a Kubernetes cluster running with cloud-controller-manager. It supports deploying &lt;code>Kubernetes azure-cloud-controller-manager&lt;/code> for Kubernetes v1.16+.&lt;/p>
&lt;h2 id="azuredisk-and-azurefile">AzureDisk and AzureFile&lt;/h2>
&lt;p>AzureDisk and AzureFile volume plugins are not supported with external coud provider (See &lt;a href="https://github.com/kubernetes/kubernetes/issues/71018">kubernetes/kubernetes#71018&lt;/a> for explanations).&lt;/p>
&lt;p>Hence, &lt;a href="https://github.com/kubernetes-sigs/azuredisk-csi-driver">azuredisk-csi-driver&lt;/a> and &lt;a href="https://github.com/kubernetes-sigs/azurefile-csi-driver">azurefile-csi-driver&lt;/a> should be used for persistent volumes.&lt;/p>
&lt;h3 id="deploy-azuredisk-csi-plugin">Deploy AzureDisk CSI plugin&lt;/h3>
&lt;p>Run following commands:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/azuredisk-csi-driver/master/deploy/csi-azuredisk-driver.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/azuredisk-csi-driver/master/deploy/crd-csi-node-info.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/azuredisk-csi-driver/master/deploy/rbac-csi-azuredisk-controller.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/azuredisk-csi-driver/master/deploy/csi-azuredisk-controller.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/azuredisk-csi-driver/master/deploy/csi-azuredisk-node.yaml
&lt;span style="color:#8f5902;font-style:italic"># skip below yaml configurations if snapshot feature(only available from v1.17.0) will not be used&lt;/span>
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/azuredisk-csi-driver/master/deploy/crd-csi-snapshot.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/azuredisk-csi-driver/master/deploy/rbac-csi-snapshot-controller.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/azuredisk-csi-driver/master/deploy/csi-snapshot-controller.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>See &lt;a href="https://github.com/kubernetes-sigs/azuredisk-csi-driver">azuredisk-csi-driver&lt;/a> for more details.&lt;/p>
&lt;h3 id="deploy-azurefile-csi-plugin">Deploy AzureFile CSI plugin&lt;/h3>
&lt;p>Run following commands:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/azurefile-csi-driver/master/deploy/crd-csi-driver-registry.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/azurefile-csi-driver/master/deploy/crd-csi-node-info.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/azurefile-csi-driver/master/deploy/rbac-csi-azurefile-controller.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/azurefile-csi-driver/master/deploy/csi-azurefile-controller.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/azurefile-csi-driver/master/deploy/csi-azurefile-node.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>See &lt;a href="https://github.com/kubernetes-sigs/azurefile-csi-driver">azurefile-csi-driver&lt;/a> for more details.&lt;/p>
&lt;h3 id="change-default-storage-class">Change default storage class&lt;/h3>
&lt;p>Follow the steps bellow if you want change the current default storage class to AzureDisk CSI driver.&lt;/p>
&lt;p>First, delete the default storage class:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">kubectl delete storageclass default
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then create a new storage class named &lt;code>default&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">cat &lt;span style="color:#4e9a06">&amp;lt;&amp;lt;EOF | kubectl apply -f-
&lt;/span>&lt;span style="color:#4e9a06">apiVersion: storage.k8s.io/v1
&lt;/span>&lt;span style="color:#4e9a06">kind: StorageClass
&lt;/span>&lt;span style="color:#4e9a06">metadata:
&lt;/span>&lt;span style="color:#4e9a06"> annotations:
&lt;/span>&lt;span style="color:#4e9a06"> storageclass.beta.kubernetes.io/is-default-class: &amp;#34;true&amp;#34;
&lt;/span>&lt;span style="color:#4e9a06"> name: default
&lt;/span>&lt;span style="color:#4e9a06">provisioner: disk.csi.azure.com
&lt;/span>&lt;span style="color:#4e9a06">parameters:
&lt;/span>&lt;span style="color:#4e9a06"> skuname: Standard_LRS # available values: Standard_LRS, Premium_LRS, StandardSSD_LRS and UltraSSD_LRS
&lt;/span>&lt;span style="color:#4e9a06"> kind: managed # value &amp;#34;dedicated&amp;#34;, &amp;#34;shared&amp;#34; are deprecated since it&amp;#39;s using unmanaged disk
&lt;/span>&lt;span style="color:#4e9a06"> cachingMode: ReadOnly
&lt;/span>&lt;span style="color:#4e9a06">reclaimPolicy: Delete
&lt;/span>&lt;span style="color:#4e9a06">volumeBindingMode: Immediate
&lt;/span>&lt;span style="color:#4e9a06">EOF&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="development">Development&lt;/h2>
&lt;p>Build project:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">make
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Build image:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#000">IMAGE_REGISTRY&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;registry&amp;gt; make image
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Run unit tests:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">make test-unit
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Updating dependency: (please check &lt;a href="../dep">Dependency management&lt;/a> for additional information)&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">make update
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="limitations">Limitations&lt;/h2>
&lt;p>Because &lt;a href="https://kubernetes-csi.github.io/docs/">CSI&lt;/a> is not ready on Windows, AzureDisk/AzureFile CSI drivers don't support Windows either. If you have Windows nodes in the cluster, please use kube-controller-manager instead of cloud-controller-manager.&lt;/p></description></item><item><title>Docs: Azure LoadBalancer</title><link>https://nilo19.github.io/cloud-provider-azure/docs/services/readme/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/docs/services/readme/</guid><description>
&lt;p>The way Azure defines a LoadBalancer is different from GCE or AWS. Azure's LB can have multiple frontend IP refs. GCE and AWS only allow one, if you want more, you would need multiple LB's. Since Public IP's are not part of the LB in Azure, an NSG is not part of the LB in Azure either. However, you cannot delete them in parallel, a Public IP can only be deleted after the LB's frontend IP ref is removed.&lt;/p>
&lt;p>The different Azure Resources such as LB, Public IP, and NSG are the same tier of Azure resources and circular dependencies need to be avoided. In another words, they should only depend on service state.&lt;/p>
&lt;p>By default the basic SKU is selected for a load balancer. Services can be annotated to allow auto selection of available load balancers. Service annotations can also be used to provide specific availability sets that host the load balancers. Note that in case of auto selection or specific availability set selection, services are currently not auto-reassigned to an available loadbalancer when the availability set is lost in case of downtime or cluster scale down.&lt;/p>
&lt;h2 id="loadbalancer-annotations">LoadBalancer annotations&lt;/h2>
&lt;p>Below is a list of annotations supported for Kubernetes services with type &lt;code>LoadBalancer&lt;/code>:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Annotation&lt;/th>
&lt;th>Value&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>Kubernetes Version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>service.beta.kubernetes.io/azure-load-balancer-internal&lt;/code>&lt;/td>
&lt;td>&lt;code>true&lt;/code> or &lt;code>false&lt;/code>&lt;/td>
&lt;td>Specify whether the load balancer should be internal. It’s defaulting to public if not set.&lt;/td>
&lt;td>v1.10.0 and later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>service.beta.kubernetes.io/azure-load-balancer-internal-subnet&lt;/code>&lt;/td>
&lt;td>Name of the subnet&lt;/td>
&lt;td>Specify which subnet the internal load balancer should be bound to. It’s defaulting to the subnet configured in cloud config file if not set.&lt;/td>
&lt;td>v1.10.0 and later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>service.beta.kubernetes.io/azure-load-balancer-mode&lt;/code>&lt;/td>
&lt;td>&lt;code>auto&lt;/code>, &lt;code>{name1},{name2}&lt;/code>&lt;/td>
&lt;td>Specify the Azure load balancer selection algorithm based on availability sets. There are currently three possible load balancer selection modes : default, auto or &amp;ldquo;{name1}, {name2}&amp;quot;. This is only working for basic LB (see below for how it works)&lt;/td>
&lt;td>v1.10.0 and later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>service.beta.kubernetes.io/azure-dns-label-name&lt;/code>&lt;/td>
&lt;td>Name of the PIP DNS label&lt;/td>
&lt;td>Specify the DNS label name for the service's public IP address (PIP). If it is set to empty string, DNS in PIP would be deleted. Because of a bug, before v1.15.10/v1.16.7/v1.17.3, the DNS label on PIP would also be deleted if the annotation is not specified.&lt;/td>
&lt;td>v1.15.0 and later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>service.beta.kubernetes.io/azure-shared-securityrule&lt;/code>&lt;/td>
&lt;td>&lt;code>true&lt;/code> or &lt;code>false&lt;/code>&lt;/td>
&lt;td>Specify that the service should be exposed using an Azure security rule that may be shared with another service, trading specificity of rules for an increase in the number of services that can be exposed. This relies on the Azure &amp;ldquo;augmented security rules&amp;rdquo; feature.&lt;/td>
&lt;td>v1.10.0 and later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>service.beta.kubernetes.io/azure-load-balancer-resource-group&lt;/code>&lt;/td>
&lt;td>Name of the PIP resource group&lt;/td>
&lt;td>Specify the resource group of the service's PIP that are not in the same resource group as the cluster.&lt;/td>
&lt;td>v1.10.0 and later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>service.beta.kubernetes.io/azure-allowed-service-tags&lt;/code>&lt;/td>
&lt;td>List of allowed service tags&lt;/td>
&lt;td>Specify a list of allowed &lt;a href="https://docs.microsoft.com/en-us/azure/virtual-network/security-overview#service-tags">service tags&lt;/a> separated by comma.&lt;/td>
&lt;td>v1.11.0 and later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>service.beta.kubernetes.io/azure-load-balancer-tcp-idle-timeout&lt;/code>&lt;/td>
&lt;td>TCP idle timeouts in minutes&lt;/td>
&lt;td>Specify the time, in minutes, for TCP connection idle timeouts to occur on the load balancer. Default and minimum value is 4. Maximum value is 30. Must be an integer.&lt;/td>
&lt;td>v1.11.4, v1.12.0 and later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>service.beta.kubernetes.io/azure-pip-name&lt;/code>|Name of PIP&lt;/td>
&lt;td>Specify the PIP that will be applied to load balancer&lt;/td>
&lt;td>v1.16 and later&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>service.beta.kubernetes.io/azure-load-balancer-disable-tcp-reset&lt;/code>|&lt;code>true&lt;/code>|Disable &lt;code>enableTcpReset&lt;/code> for SLB&lt;/td>
&lt;td>v1.16-v1.18. The annotation has been deprecated and would be removed in a future release.&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="load-balancer-selection-modes">Load balancer selection modes&lt;/h3>
&lt;p>There are currently three possible load balancer selection modes :&lt;/p>
&lt;ol>
&lt;li>Default mode - service has no annotation (&amp;ldquo;service.beta.kubernetes.io/azure-load-balancer-mode&amp;rdquo;). In this case the Loadbalancer of the primary Availability set is selected&lt;/li>
&lt;li>&amp;ldquo;&lt;strong>auto&lt;/strong>&amp;rdquo; mode - service is annotated with &lt;strong>auto&lt;/strong> value, this when loadbalancer from any availability set is selected which has the minimum rules associated with it.&lt;/li>
&lt;li>&amp;ldquo;{name1}, {name2}&amp;rdquo; mode - this is when the load balancer from the specified availability sets is selected that has the minimum rules associated with it.&lt;/li>
&lt;/ol>
&lt;p>The selection mode for a load balancer only works for Azure's basic SKU (see below) because of the difference in backend pool endpoints:&lt;/p>
&lt;ul>
&lt;li>Standard SKU supports any virtual machine in a single virtual network, including a mix of virtual machines, availability sets, and virtual machine scale sets. So all the nodes would be added to the same standard LB backend pool with a max size of 1000.&lt;/li>
&lt;li>Basic SKU only supports virtual machines in a single availability set or a virtual machine scale set. Only nodes with the same availability set or virtual machine scale set would be added to the basic LB backend pool.&lt;/li>
&lt;/ul>
&lt;h2 id="loadbalancer-skus">LoadBalancer SKUs&lt;/h2>
&lt;p>Azure cloud provider supports both &lt;code>basic&lt;/code> and &lt;code>standard&lt;/code> SKU load balancers, which can be set via &lt;code>loadBalancerSku&lt;/code> option in &lt;a href="../../config">cloud config file&lt;/a>. A list of differences between these two SKUs can be found &lt;a href="https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-standard-overview#why-use-standard-load-balancer">here&lt;/a>.&lt;/p>
&lt;blockquote>
&lt;p>Note that the public IPs used in load balancer frontend configurations should be the same SKU. That is a standard SKU public IP for standard load balancer and a basic SKU public IP for a basic load balancer.&lt;/p>
&lt;/blockquote>
&lt;p>Azure doesn’t support a network interface joining load balancers with different SKUs, hence migration dynamically between them is not supported.&lt;/p>
&lt;blockquote>
&lt;p>If you do require migration, please delete all services with type &lt;code>LoadBalancer&lt;/code> (or change to other type)&lt;/p>
&lt;/blockquote>
&lt;h3 id="outbound-connectivity">Outbound connectivity&lt;/h3>
&lt;p>&lt;a href="https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-outbound-connections">Outbound connectivity&lt;/a> is also different between the two load balancer SKUs:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>For the basic SKU, the outbound connectivity is opened by default. If multiple frontends are set, then the outbound IP is selected randomly (and configurable) from them.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>For the standard SKU, the outbound connectivity is disabled by default. There are two ways to open the outbound connectivity: use a standard public IP with the standard load balancer or define outbound rules.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="standard-loadbalancer">Standard LoadBalancer&lt;/h3>
&lt;p>Because the load balancer in a Kubernetes cluster is managed by the Azure cloud provider and it may change dynamically (e.g. the public load balancer would be deleted if no services defined with type &lt;code>LoadBalancer&lt;/code>), &lt;a href="https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-outbound-rules-overview">outbound rules&lt;/a> are the recommended path if you want to ensure the outbound connectivity for all nodes.&lt;/p>
&lt;blockquote>
&lt;p>Especially note:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>In the context of outbound connectivity, a single standalone VM, all the VM's in an Availability Set, all the instances in a VMSS behave as a group. This means, if a single VM in an Availability Set is associated with a Standard SKU, all VM instances within this Availability Set now behave by the same rules as if they are associated with Standard SKU, even if an individual instance is not directly associated with it.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Public IP's used as instance-level public IP are mutually exclusive with outbound rules.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Here is the recommend way to define the &lt;a href="https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-outbound-rules-overview">outbound rules&lt;/a> when using separate provisioning tools:&lt;/p>
&lt;ul>
&lt;li>Create a separate IP (or multiple IPs for scale) in standard SKU for outbound rules. Make use of the &lt;a href="https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-outbound-rules-overview#snatports">allocatedOutboundPorts&lt;/a> parameter to allocate sufficient ports for your desired scenario scale.&lt;/li>
&lt;li>Create a separate pool definition for outbound, and ensure all virtual machines or VMSS virtual machines are in this pool. Azure cloud provider will manage the load balancer rules with another pool, so that provisioning tools and the Azure cloud provider won't affect each other.&lt;/li>
&lt;li>Define inbound with load balancing rules and inbound NAT rules as needed, and set &lt;code>disableOutboundSNAT&lt;/code> to true on the load balancing rule(s). Don't rely on the side effect from these rules for outbound connectivity. It makes it messier than it needs to be and limits your options. Use inbound NAT rules to create port forwarding mappings for SSH access to the VM's rather than burning public IPs per instance.&lt;/li>
&lt;/ul></description></item><item><title>Contribute: Contributing</title><link>https://nilo19.github.io/cloud-provider-azure/contribute/contributing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/contribute/contributing/</guid><description>
&lt;p>Thanks for taking the time to join our community and start contributing!&lt;/p>
&lt;p>The &lt;a href="https://github.com/kubernetes/community/blob/master/contributors/guide/README.md">Contributor Guide&lt;/a>
provides detailed instructions on how to get your ideas and bug fixes seen and accepted.&lt;/p>
&lt;p>Please remember to sign the &lt;a href="https://github.com/kubernetes/community/blob/master/CLA.md">CNCF CLA&lt;/a> and
read and observe the &lt;a href="https://github.com/cncf/foundation/blob/master/code-of-conduct.md">Code of Conduct&lt;/a>.&lt;/p></description></item><item><title>Docs: Azure Permissions</title><link>https://nilo19.github.io/cloud-provider-azure/docs/permission/azure-permissions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/docs/permission/azure-permissions/</guid><description>
&lt;p>Azure cloud provider requires a set of permissions to manage the Azure resources. Here is a list of all permissions and reasons of why they're required.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#8f5902;font-style:italic">// Required to create, delete or update LoadBalancer for LoadBalancer service
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">loadBalancers&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">delete&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">loadBalancers&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">loadBalancers&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">write&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to allow query, create or delete public IPs for LoadBalancer service
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">publicIPAddresses&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">delete&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">publicIPAddresses&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">publicIPAddresses&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">write&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required if public IPs from another resource group are used for LoadBalancer service
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#8f5902;font-style:italic">// This is because of the linked access check when adding the public IP to LB frontendIPConfiguration
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">publicIPAddresses&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">join&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">action&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to create or delete security rules for LoadBalancer service
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">networkSecurityGroups&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">networkSecurityGroups&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">write&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to create, delete or update AzureDisks
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">disks&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">delete&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">disks&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">disks&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">write&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">locations&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">DiskOperations&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to create, update or delete storage accounts for AzureFile or AzureDisk
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Storage&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">storageAccounts&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">delete&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Storage&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">storageAccounts&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">listKeys&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">action&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Storage&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">storageAccounts&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Storage&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">storageAccounts&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">write&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Storage&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">operations&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to create, delete or update routeTables and routes for nodes
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">routeTables&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">routeTables&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">routes&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">delete&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">routeTables&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">routes&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">routeTables&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">routes&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">write&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">routeTables&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">write&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to query information for VM (e.g. zones, faultdomain, size and data disks)
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualMachines&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to attach AzureDisks to VM
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualMachines&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">write&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to query information for vmssVM (e.g. zones, faultdomain, size and data disks)
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualMachineScaleSets&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualMachineScaleSets&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualMachines&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualMachineScaleSets&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualmachines&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">instanceView&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to add VM to LoadBalancer backendAddressPools
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">networkInterfaces&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">write&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to add vmss to LoadBalancer backendAddressPools
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualMachineScaleSets&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">write&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to attach AzureDisks and add vmssVM to LB
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualMachineScaleSets&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualmachines&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">write&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to upgrade VMSS models to latest for all instances
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#8f5902;font-style:italic">// only needed for Kubernetes 1.11.0-1.11.9, 1.12.0-1.12.8, 1.13.0-1.13.5, 1.14.0-1.14.1
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualMachineScaleSets&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">manualupgrade&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">action&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to query internal IPs and loadBalancerBackendAddressPools for VM
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">networkInterfaces&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to query internal IPs and loadBalancerBackendAddressPools for vmssVM
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualMachineScaleSets&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualMachines&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">networkInterfaces&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to get public IPs for vmssVM
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualMachineScaleSets&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualMachines&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">networkInterfaces&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">ipconfigurations&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">publicipaddresses&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to check whether subnet existing for ILB in another resource group
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualNetworks&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Network&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">virtualNetworks&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">subnets&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to create, update or delete snapshots for AzureDisk
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">snapshots&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">delete&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">snapshots&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">snapshots&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">write&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// Required to get vm sizes for getting AzureDisk volume limit
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">locations&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">vmSizes&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;span style="color:#000">Microsoft&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Compute&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">locations&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">operations&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">read&lt;/span>
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: Cloud Provider Config</title><link>https://nilo19.github.io/cloud-provider-azure/docs/config/cloud-provider-config/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/docs/config/cloud-provider-config/</guid><description>
&lt;p>This doc describes cloud provider config file, which is to be used via the &lt;code>--cloud-config&lt;/code> flag of azure-cloud-controller-manager.&lt;/p>
&lt;p>Here is a config file sample:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;cloud&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;AzurePublicCloud&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;tenantId&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;0000000-0000-0000-0000-000000000000&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;aadClientId&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;0000000-0000-0000-0000-000000000000&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;aadClientSecret&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;0000000-0000-0000-0000-000000000000&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;subscriptionId&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;0000000-0000-0000-0000-000000000000&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;resourceGroup&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;&amp;lt;name&amp;gt;&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;location&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;eastus&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;subnetName&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;&amp;lt;name&amp;gt;&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;securityGroupName&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;&amp;lt;name&amp;gt;&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;vnetName&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;&amp;lt;name&amp;gt;&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;vnetResourceGroup&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;routeTableName&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;&amp;lt;name&amp;gt;&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;primaryAvailabilitySetName&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;&amp;lt;name&amp;gt;&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;routeTableResourceGroup&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;&amp;lt;name&amp;gt;&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;cloudProviderBackoff&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#204a87;font-weight:bold">false&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;useManagedIdentityExtension&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#204a87;font-weight:bold">false&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;useInstanceMetadata&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#204a87;font-weight:bold">true&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note: All values are of type &lt;code>string&lt;/code> if not explicitly called out.&lt;/p>
&lt;h2 id="auth-configs">Auth configs&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Name&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>Remark&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>cloud&lt;/td>
&lt;td>The cloud environment identifier&lt;/td>
&lt;td>Valid values could be found &lt;a href="https://github.com/Azure/go-autorest/blob/v9.9.0/autorest/azure/environments.go#L29">here&lt;/a>. Default to &lt;code>AzurePublicCloud&lt;/code>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>tenantID&lt;/td>
&lt;td>The AAD Tenant ID for the Subscription that the cluster is deployed in&lt;/td>
&lt;td>&lt;strong>Required&lt;/strong>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>aadClientID&lt;/td>
&lt;td>The ClientID for an AAD application with RBAC access to talk to Azure RM APIs&lt;/td>
&lt;td>Used for service principal authn.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>aadClientSecret&lt;/td>
&lt;td>The ClientSecret for an AAD application with RBAC access to talk to Azure RM APIs&lt;/td>
&lt;td>Used for service principal authn.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>aadClientCertPath&lt;/td>
&lt;td>The path of a client certificate for an AAD application with RBAC access to talk to Azure RM APIs&lt;/td>
&lt;td>Used for client cert authn.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>aadClientCertPassword&lt;/td>
&lt;td>The password of the client certificate for an AAD application with RBAC access to talk to Azure RM APIs&lt;/td>
&lt;td>Used for client cert authn.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>useManagedIdentityExtension&lt;/td>
&lt;td>Use managed service identity for the virtual machine to access Azure ARM APIs&lt;/td>
&lt;td>Boolean type, default to false.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>userAssignedIdentityID&lt;/td>
&lt;td>The Client ID of the user assigned MSI which is assigned to the underlying VMs&lt;/td>
&lt;td>Required for user-assigned managed identity.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>subscriptionId&lt;/td>
&lt;td>The ID of the Azure Subscription that the cluster is deployed in&lt;/td>
&lt;td>&lt;strong>Required&lt;/strong>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>identitySystem&lt;/td>
&lt;td>The identity system for AzureStack. Supported values are: ADFS&lt;/td>
&lt;td>Only used for AzureStack&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>networkResourceTenantID&lt;/td>
&lt;td>The AAD Tenant ID for the Subscription that the network resources are deployed in&lt;/td>
&lt;td>Optional. Supported since v1.18.0. Only used for hosting network resources in different AAD Tenant and Subscription than those for the cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>networkResourceSubscriptionID&lt;/td>
&lt;td>The ID of the Azure Subscription that the network resources are deployed in&lt;/td>
&lt;td>Optional. Supported since v1.18.0. Only used for hosting network resources in different AAD Tenant and Subscription than those for the cluster.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Note: Cloud provider currently supports three authentication methods, you can choose one combination of them:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.microsoft.com/en-us/azure/active-directory/managed-service-identity/overview">Managed Identity&lt;/a>:
&lt;ul>
&lt;li>For system-assigned managed identity: set &lt;code>useManagedIdentityExtension&lt;/code> to true&lt;/li>
&lt;li>For user-assigned managed identity: set &lt;code>useManagedIdentityExtension&lt;/code> to true and also set &lt;code>userAssignedIdentityID&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/aks-engine/blob/master/docs/topics/service-principals.md">Service Principal&lt;/a>: set &lt;code>aadClientID&lt;/code> and &lt;code>aadClientSecret&lt;/code>&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-protocols-oauth-service-to-service">Client Certificate&lt;/a>: set &lt;code>aadClientCertPath&lt;/code> and &lt;code>aadClientCertPassword&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>If more than one value is set, the order is &lt;code>Managed Identity&lt;/code> &amp;gt; &lt;code>Service Principal&lt;/code> &amp;gt; &lt;code>Client Certificate&lt;/code>.&lt;/p>
&lt;h2 id="cluster-config">Cluster config&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Name&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>Remark&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>resourceGroup&lt;/td>
&lt;td>The name of the resource group that the cluster is deployed in&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>location&lt;/td>
&lt;td>The location of the resource group that the cluster is deployed in&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>vnetName&lt;/td>
&lt;td>The name of the VNet that the cluster is deployed in&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>vnetResourceGroup&lt;/td>
&lt;td>The name of the resource group that the Vnet is deployed in&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>subnetName&lt;/td>
&lt;td>The name of the subnet that the cluster is deployed in&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>securityGroupName&lt;/td>
&lt;td>The name of the security group attached to the cluster's subnet&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>routeTableName&lt;/td>
&lt;td>The name of the route table attached to the subnet that the cluster is deployed in&lt;/td>
&lt;td>Optional in 1.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>primaryAvailabilitySetName&lt;a href="#primaryavailabilitysetname">*&lt;/a>&lt;/td>
&lt;td>The name of the availability set that should be used as the load balancer backend&lt;/td>
&lt;td>Optional&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>vmType&lt;/td>
&lt;td>The type of azure nodes. Candidate values are: &lt;code>vmss&lt;/code> and &lt;code>standard&lt;/code>|Optional, default to &lt;code>standard&lt;/code>|&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>primaryScaleSetName&lt;a href="#primaryscalesetname">*&lt;/a>&lt;/td>
&lt;td>The name of the scale set that should be used as the load balancer backend&lt;/td>
&lt;td>Optional&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cloudProviderBackoff&lt;/td>
&lt;td>Enable exponential backoff to manage resource request retries&lt;/td>
&lt;td>Boolean value, default to false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cloudProviderBackoffRetries&lt;/td>
&lt;td>Backoff retry limit&lt;/td>
&lt;td>Integer value, valid if &lt;code>cloudProviderBackoff&lt;/code> is true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cloudProviderBackoffExponent&lt;/td>
&lt;td>Backoff exponent&lt;/td>
&lt;td>Float value, valid if &lt;code>cloudProviderBackoff&lt;/code> is true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cloudProviderBackoffDuration&lt;/td>
&lt;td>Backoff duration&lt;/td>
&lt;td>Integer value, valid if &lt;code>cloudProviderBackoff&lt;/code> is true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cloudProviderBackoffJitter&lt;/td>
&lt;td>Backoff jitter&lt;/td>
&lt;td>Float value, valid if &lt;code>cloudProviderBackoff&lt;/code> is true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cloudProviderBackoffMode&lt;/td>
&lt;td>Backoff mode, supported values are &amp;ldquo;v2&amp;rdquo; and &amp;ldquo;default&amp;rdquo;. Note that &amp;ldquo;v2&amp;rdquo; has been deprecated since v1.18.0.&lt;/td>
&lt;td>Default to &amp;ldquo;default&amp;rdquo;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cloudProviderRateLimit&lt;/td>
&lt;td>Enable rate limiting&lt;/td>
&lt;td>Boolean value, default to false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cloudProviderRateLimitQPS&lt;/td>
&lt;td>Rate limit QPS (Read)&lt;/td>
&lt;td>Float value, valid if &lt;code>cloudProviderRateLimit&lt;/code> is true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cloudProviderRateLimitBucket&lt;/td>
&lt;td>Rate limit Bucket Size&lt;/td>
&lt;td>Integar value, valid if &lt;code>cloudProviderRateLimit&lt;/code> is true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cloudProviderRateLimitQPSWrite&lt;/td>
&lt;td>Rate limit QPS (Write)&lt;/td>
&lt;td>Float value, valid if &lt;code>cloudProviderRateLimit&lt;/code> is true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cloudProviderRateLimitBucketWrite&lt;/td>
&lt;td>Rate limit Bucket Size&lt;/td>
&lt;td>Integer value, valid if &lt;code>cloudProviderRateLimit&lt;/code> is true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>useInstanceMetadata&lt;/td>
&lt;td>Use instance metadata service where possible&lt;/td>
&lt;td>Boolean value, default to false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>loadBalancerSku&lt;/td>
&lt;td>Sku of Load Balancer and Public IP. Candidate values are: &lt;code>basic&lt;/code> and &lt;code>standard&lt;/code>.&lt;/td>
&lt;td>Default to &lt;code>basic&lt;/code>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>loadBalancerResourceGroup&lt;/td>
&lt;td>Resource group name of the load balancer user want to use, default value is the name of cluster's resource group&lt;/td>
&lt;td>String value of rg's name, optional&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>loadBalancerName&lt;/td>
&lt;td>The name of the load balancer user want to use. If not set, default naming pattern is used.&lt;/td>
&lt;td>String value, optional&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>excludeMasterFromStandardLB&lt;/td>
&lt;td>ExcludeMasterFromStandardLB excludes master nodes from standard load balancer.&lt;/td>
&lt;td>Boolean value, default to true.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>disableOutboundSNAT&lt;/td>
&lt;td>Disable outbound SNAT for SLB&lt;/td>
&lt;td>Default to false and available since v1.11.9, v1.12.7, v1.13.5 and v1.14.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>maximumLoadBalancerRuleCount&lt;/td>
&lt;td>Maximum allowed LoadBalancer Rule Count is the limit enforced by Azure Load balancer&lt;/td>
&lt;td>Integer value, default to &lt;a href="https://github.com/kubernetes/kubernetes/blob/v1.10.0/pkg/cloudprovider/providers/azure/azure.go#L48">148&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>routeTableResourceGroup&lt;/td>
&lt;td>The resource group name for routeTable&lt;/td>
&lt;td>Default same as resourceGroup and available since v1.15.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cloudConfigType&lt;/td>
&lt;td>The cloud configure type for Azure cloud provider. Supported values are file, secret and merge.&lt;/td>
&lt;td>Default to &lt;code>merge&lt;/code>. and available since v1.15.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>loadBalancerName&lt;/td>
&lt;td>Working together with loadBalancerResourceGroup to determine the LB name in a different resource group&lt;/td>
&lt;td>Since v1.18.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>loadBalancerResourceGroup&lt;/td>
&lt;td>The load balancer resource group name, which is different from node resource group&lt;/td>
&lt;td>Since v1.18.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>disableAvailabilitySetNodes&lt;/td>
&lt;td>Disable supporting for AvailabilitySet virtual machines in vmss cluster. It should be only used when vmType is &amp;ldquo;vmss&amp;rdquo; and all the nodes (including master) are VMSS virtual machines&lt;/td>
&lt;td>Since v1.18.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="primaryavailabilitysetname">primaryAvailabilitySetName&lt;/h3>
&lt;p>If this is set, the Azure cloudprovider will only add nodes from that availability set to the load
balancer backend pool. If this is not set, and multiple agent pools (availability sets) are used, then
the cloudprovider will try to add all nodes to a single backend pool which is forbidden.
In other words, if you use multiple agent pools (availability sets), you MUST set this field.&lt;/p>
&lt;h3 id="primaryscalesetname">primaryScaleSetName&lt;/h3>
&lt;p>If this is set, the Azure cloudprovider will only add nodes from that scale set to the load
balancer backend pool. If this is not set, and multiple agent pools (scale sets) are used, then
the cloudprovider will try to add all nodes to a single backend pool which is forbidden when using Load Balancer Basic SKU.
In other words, if you use multiple agent pools (scale sets), and &lt;code>loadBalancerSku&lt;/code> is set to &lt;code>basic&lt;/code> you MUST set this field.&lt;/p>
&lt;h3 id="excludemasterfromstandardlb">excludeMasterFromStandardLB&lt;/h3>
&lt;p>Master nodes are not added to the backends of Azure Load Balancer (ALB) if &lt;code>excludeMasterFromStandardLB&lt;/code> is set.&lt;/p>
&lt;p>By default, if nodes are labeled with &lt;code>node-role.kubernetes.io/master&lt;/code>, they would also be excluded from ALB. If you want to add the master nodes to ALB, &lt;code>excludeMasterFromStandardLB&lt;/code> should be set to false and label &lt;code>node-role.kubernetes.io/master&lt;/code> should be removed if it has already been applied.&lt;/p>
&lt;h3 id="setting-azure-cloud-provider-from-kubernetes-secrets">Setting Azure cloud provider from Kubernetes secrets&lt;/h3>
&lt;p>Since v1.15.0, Azure cloud provider supports reading the cloud config from Kubernetes secrets. The secret is a serialized version of &lt;code>azure.json&lt;/code> file with key &lt;code>cloud-config&lt;/code>. The secret should be put in &lt;code>kube-system&lt;/code> namespace and its name should be &lt;code>azure-cloud-provider&lt;/code>.&lt;/p>
&lt;p>To enable this feature, set &lt;code>cloudConfigType&lt;/code> to &lt;code>secret&lt;/code> or &lt;code>merge&lt;/code> (default is &lt;code>merge&lt;/code>). All supported values for this option are:&lt;/p>
&lt;ul>
&lt;li>&lt;code>file&lt;/code>: The cloud provider configuration is read from cloud-config file.&lt;/li>
&lt;li>&lt;code>secret&lt;/code>: the cloud provider configuration must be overridden by the secret.&lt;/li>
&lt;li>&lt;code>merge&lt;/code>: the cloud provider configuration can be optionally overridden by a secret when it is set explicitly in the secret, this is default value.&lt;/li>
&lt;/ul>
&lt;p>Since Azure cloud provider would read Kubernetes secrets, the following RBAC should also be configured:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">---&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>apiVersion&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>rbac.authorization.k8s.io/v1beta1&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>kind&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>ClusterRole&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>metadata&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>labels&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kubernetes.io/cluster-service&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#4e9a06">&amp;#34;true&amp;#34;&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>name&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>system&lt;span style="color:#000;font-weight:bold">:&lt;/span>azure-cloud-provider-secret-getter&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>rules&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>-&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>apiGroups&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>resources&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;secrets&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>resourceNames&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;azure-cloud-provider&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>verbs&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>-&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>get&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>---&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>apiVersion&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>rbac.authorization.k8s.io/v1beta1&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>kind&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>ClusterRoleBinding&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>metadata&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>labels&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kubernetes.io/cluster-service&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#4e9a06">&amp;#34;true&amp;#34;&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>name&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>system&lt;span style="color:#000;font-weight:bold">:&lt;/span>azure-cloud-provider-secret-getter&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>roleRef&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>apiGroup&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>rbac.authorization.k8s.io&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kind&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>ClusterRole&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>name&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>system&lt;span style="color:#000;font-weight:bold">:&lt;/span>azure-cloud-provider-secret-getter&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>subjects&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>-&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kind&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>ServiceAccount&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>name&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>azure-cloud-provider&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>namespace&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kube-system&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="per-client-rate-limiting">per client rate limiting&lt;/h3>
&lt;p>Since v1.18.0, the original global rate limiting has been switched to per-client. A set of new rate limit configure options are introduced for each client, which includes:&lt;/p>
&lt;ul>
&lt;li>routeRateLimit&lt;/li>
&lt;li>SubnetsRateLimit&lt;/li>
&lt;li>InterfaceRateLimit&lt;/li>
&lt;li>RouteTableRateLimit&lt;/li>
&lt;li>LoadBalancerRateLimit&lt;/li>
&lt;li>PublicIPAddressRateLimit&lt;/li>
&lt;li>SecurityGroupRateLimit&lt;/li>
&lt;li>VirtualMachineRateLimit&lt;/li>
&lt;li>StorageAccountRateLimit&lt;/li>
&lt;li>DiskRateLimit&lt;/li>
&lt;li>SnapshotRateLimit&lt;/li>
&lt;li>VirtualMachineScaleSetRateLimit&lt;/li>
&lt;li>VirtualMachineSizeRateLimit&lt;/li>
&lt;/ul>
&lt;p>The original rate limiting options (&amp;ldquo;cloudProviderRateLimitBucket&amp;rdquo;, &amp;ldquo;cloudProviderRateLimitBucketWrite&amp;rdquo;, &amp;ldquo;cloudProviderRateLimitQPS&amp;rdquo;, &amp;ldquo;cloudProviderRateLimitQPSWrite&amp;rdquo;) are still supported, and they would be the default values if per-client rate limiting is not configured.&lt;/p>
&lt;p>Here is an example of per-client config:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#a40000">/&lt;/span>&lt;span style="color:#a40000">/&lt;/span> &lt;span style="color:#a40000">d&lt;/span>&lt;span style="color:#a40000">e&lt;/span>&lt;span style="color:#a40000">f&lt;/span>&lt;span style="color:#a40000">a&lt;/span>&lt;span style="color:#a40000">u&lt;/span>&lt;span style="color:#a40000">l&lt;/span>&lt;span style="color:#a40000">t&lt;/span> &lt;span style="color:#a40000">r&lt;/span>&lt;span style="color:#a40000">a&lt;/span>&lt;span style="color:#a40000">t&lt;/span>&lt;span style="color:#a40000">e&lt;/span> &lt;span style="color:#a40000">l&lt;/span>&lt;span style="color:#a40000">i&lt;/span>&lt;span style="color:#a40000">m&lt;/span>&lt;span style="color:#a40000">i&lt;/span>&lt;span style="color:#a40000">t&lt;/span> &lt;span style="color:#a40000">(&lt;/span>&lt;span style="color:#a40000">e&lt;/span>&lt;span style="color:#a40000">n&lt;/span>&lt;span style="color:#a40000">a&lt;/span>&lt;span style="color:#a40000">b&lt;/span>&lt;span style="color:#a40000">l&lt;/span>&lt;span style="color:#a40000">e&lt;/span>&lt;span style="color:#a40000">d&lt;/span>&lt;span style="color:#a40000">)&lt;/span>&lt;span style="color:#a40000">.&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;cloudProviderRatelimit&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#204a87;font-weight:bold">true&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;cloudProviderRateLimitBucket&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;cloudProviderRateLimitBucketWrite&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;cloudProviderRateLimitQPS&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;cloudProviderRateLimitQPSWrite&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;virtualMachineScaleSetRateLimit&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span> &lt;span style="color:#a40000">/&lt;/span>&lt;span style="color:#a40000">/&lt;/span> &lt;span style="color:#a40000">V&lt;/span>&lt;span style="color:#a40000">M&lt;/span>&lt;span style="color:#a40000">S&lt;/span>&lt;span style="color:#a40000">S&lt;/span> &lt;span style="color:#a40000">s&lt;/span>&lt;span style="color:#a40000">p&lt;/span>&lt;span style="color:#a40000">e&lt;/span>&lt;span style="color:#a40000">c&lt;/span>&lt;span style="color:#a40000">i&lt;/span>&lt;span style="color:#a40000">f&lt;/span>&lt;span style="color:#a40000">i&lt;/span>&lt;span style="color:#a40000">c&lt;/span> &lt;span style="color:#a40000">(&lt;/span>&lt;span style="color:#a40000">e&lt;/span>&lt;span style="color:#a40000">n&lt;/span>&lt;span style="color:#a40000">a&lt;/span>&lt;span style="color:#a40000">b&lt;/span>&lt;span style="color:#a40000">l&lt;/span>&lt;span style="color:#a40000">e&lt;/span>&lt;span style="color:#a40000">d&lt;/span>&lt;span style="color:#a40000">)&lt;/span>&lt;span style="color:#a40000">.&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;cloudProviderRatelimit&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#204a87;font-weight:bold">true&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;cloudProviderRateLimitBucket&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;CloudProviderRateLimitBucketWrite&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;cloudProviderRateLimitQPS&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;CloudProviderRateLimitQPSWrite&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;loadBalancerRateLimit&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span> &lt;span style="color:#a40000">/&lt;/span>&lt;span style="color:#a40000">/&lt;/span> &lt;span style="color:#a40000">L&lt;/span>&lt;span style="color:#a40000">B&lt;/span> &lt;span style="color:#a40000">s&lt;/span>&lt;span style="color:#a40000">p&lt;/span>&lt;span style="color:#a40000">e&lt;/span>&lt;span style="color:#a40000">c&lt;/span>&lt;span style="color:#a40000">i&lt;/span>&lt;span style="color:#a40000">f&lt;/span>&lt;span style="color:#a40000">i&lt;/span>&lt;span style="color:#a40000">c&lt;/span> &lt;span style="color:#a40000">(&lt;/span>&lt;span style="color:#a40000">d&lt;/span>&lt;span style="color:#a40000">i&lt;/span>&lt;span style="color:#a40000">s&lt;/span>&lt;span style="color:#a40000">a&lt;/span>&lt;span style="color:#a40000">b&lt;/span>&lt;span style="color:#a40000">l&lt;/span>&lt;span style="color:#a40000">e&lt;/span>&lt;span style="color:#a40000">d&lt;/span>&lt;span style="color:#a40000">)&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;cloudProviderRatelimit&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#204a87;font-weight:bold">false&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#a40000">.&lt;/span>&lt;span style="color:#a40000">.&lt;/span>&lt;span style="color:#a40000">.&lt;/span> &lt;span style="color:#a40000">/&lt;/span>&lt;span style="color:#a40000">/&lt;/span> &lt;span style="color:#a40000">o&lt;/span>&lt;span style="color:#a40000">t&lt;/span>&lt;span style="color:#a40000">h&lt;/span>&lt;span style="color:#a40000">e&lt;/span>&lt;span style="color:#a40000">r&lt;/span> &lt;span style="color:#a40000">c&lt;/span>&lt;span style="color:#a40000">l&lt;/span>&lt;span style="color:#a40000">o&lt;/span>&lt;span style="color:#a40000">u&lt;/span>&lt;span style="color:#a40000">d&lt;/span> &lt;span style="color:#a40000">p&lt;/span>&lt;span style="color:#a40000">r&lt;/span>&lt;span style="color:#a40000">o&lt;/span>&lt;span style="color:#a40000">v&lt;/span>&lt;span style="color:#a40000">i&lt;/span>&lt;span style="color:#a40000">d&lt;/span>&lt;span style="color:#a40000">e&lt;/span>&lt;span style="color:#a40000">r&lt;/span> &lt;span style="color:#a40000">c&lt;/span>&lt;span style="color:#a40000">o&lt;/span>&lt;span style="color:#a40000">n&lt;/span>&lt;span style="color:#a40000">f&lt;/span>&lt;span style="color:#a40000">i&lt;/span>&lt;span style="color:#a40000">g&lt;/span>&lt;span style="color:#a40000">s&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="run-kubelet-without-azure-identity">Run Kubelet without Azure identity&lt;/h2>
&lt;p>When running Kubelet with kube-controller-manager, it also supports running without Azure identity since v1.15.0.&lt;/p>
&lt;p>Both kube-controller-manager and kubelet should configure &lt;code>--cloud-provider=azure --cloud-config=/etc/kubernetes/azure.json&lt;/code>, but the contents for &lt;code>azure.json&lt;/code> are different:&lt;/p>
&lt;p>(1) For kube-controller-manager, refer the above part for setting &lt;code>azure.json&lt;/code>.&lt;/p>
&lt;p>(2) For kubelet, &lt;code>useInstanceMetadata&lt;/code> is required to be &lt;code>true&lt;/code> and Azure identities are not required. A sample for Kubelet's azure.json is&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;useInstanceMetadata&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#204a87;font-weight:bold">true&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;vmType&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;vmss&amp;#34;&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="azure-stack-configuration">Azure Stack Configuration&lt;/h2>
&lt;p>Azure Stack has different API endpoints, depending on the Azure Stack deployment. These need to be provided to the Azure SDK and currently this is done by adding an extra &lt;code>json&lt;/code> file with the arguments, as well as an environment variable pointing to this file.&lt;/p>
&lt;p>There are several available presets, namely:&lt;/p>
&lt;ul>
&lt;li>&lt;code>AzureChinaCloud&lt;/code>&lt;/li>
&lt;li>&lt;code>AzureGermanCloud&lt;/code>&lt;/li>
&lt;li>&lt;code>AzurePublicCloud&lt;/code>&lt;/li>
&lt;li>&lt;code>AzureUSGovernmentCloud&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>These are determined using &lt;code>cloud: &amp;lt;PRESET&amp;gt;&lt;/code> described above in the description of &lt;code>azure.json&lt;/code>.&lt;/p>
&lt;p>When &lt;code>cloud: AzureStackCloud&lt;/code>, the extra environment variable used by the Azure SDK to find the Azure Stack configuration file is:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Azure/go-autorest/blob/562d376/autorest/azure/environments.go#L28">&lt;code>AZURE_ENVIRONMENT_FILEPATH&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>The configuration parameters of this file:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;name&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;AzureStackCloud&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;managementPortalURL&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;publishSettingsURL&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;serviceManagementEndpoint&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;resourceManagerEndpoint&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;activeDirectoryEndpoint&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;galleryEndpoint&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;keyVaultEndpoint&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;graphEndpoint&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;serviceBusEndpoint&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;batchManagementEndpoint&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;storageEndpointSuffix&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;sqlDatabaseDNSSuffix&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;trafficManagerDNSSuffix&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;keyVaultDNSSuffix&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;serviceBusEndpointSuffix&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;serviceManagementVMDNSSuffix&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;resourceManagerVMDNSSuffix&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;containerRegistryDNSSuffix&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;cosmosDBDNSSuffix&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;tokenAudience&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;resourceIdentifiers&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;graph&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;keyVault&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;datalake&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;batch&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;operationalInsights&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;...&amp;#34;&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The full list of existing settings for the &lt;code>AzureChinaCloud&lt;/code>, &lt;code>AzureGermanCloud&lt;/code>, &lt;code>AzurePublicCloud&lt;/code> and &lt;code>AzureUSGovernmentCloud&lt;/code> is available in the source code at &lt;a href="https://github.com/Azure/go-autorest/blob/master/autorest/azure/environments.go#L51">https://github.com/Azure/go-autorest/blob/master/autorest/azure/environments.go#L51&lt;/a>&lt;/p>
&lt;h2 id="host-network-resources-in-different-aad-tenant-and-subscription">Host Network Resources in different AAD Tenant and Subscription&lt;/h2>
&lt;p>Since v1.18.0, Azure cloud provider supports hosting network resources (Virtual Network, Network Security Group, Route Table, Load Balancer and Public IP) in different AAD Tenant and Subscription than those for the cluster. To enable this feature, set &lt;code>networkResourceTenantID&lt;/code> and &lt;code>networkResourceSubscriptionID&lt;/code> in auth config. Note that the value of them need to be different than value of &lt;code>tenantID&lt;/code> and &lt;code>subscriptionID&lt;/code>.&lt;/p>
&lt;p>With this feature enabled, network resources of the cluster will be created in &lt;code>networkResourceSubscriptionID&lt;/code> in &lt;code>networkResourceTenantID&lt;/code>, and rest resources of the cluster still remain in &lt;code>subscriptionID&lt;/code> in &lt;code>tenantID&lt;/code>. Properties which specify the resource groups of network resources are compatible with this feature. For example, Virtual Network will be created in &lt;code>vnetResourceGroup&lt;/code> in &lt;code>networkResourceSubscriptionID&lt;/code> in &lt;code>networkResourceTenantID&lt;/code>.&lt;/p>
&lt;p>For authentication methods, only Service Principal supports this feature, and &lt;code>aadClientID&lt;/code> and &lt;code>aadClientSecret&lt;/code> are used to authenticate with those two AAD Tenants and Subscriptions. Managed Identity and Client Certificate doesn't support this feature. Azure Stack doesn't support this feature.&lt;/p>
&lt;h2 id="current-default-rate-limiting-values">Current default rate-limiting values&lt;/h2>
&lt;p>The following are the default rate limiting values configured in &lt;a href="https://azure.microsoft.com/en-us/services/kubernetes-service/">AKS&lt;/a> and &lt;a href="https://github.com/Azure/aks-engine">AKS-Engine&lt;/a> clusters prior to Kubernetes version v1.18.0.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json"> &lt;span style="color:#4e9a06">&amp;#34;cloudProviderBackoff&amp;#34;&lt;/span>&lt;span style="color:#a40000">:&lt;/span> &lt;span style="color:#204a87;font-weight:bold">true&lt;/span>&lt;span style="color:#a40000">,&lt;/span>
&lt;span style="color:#4e9a06">&amp;#34;cloudProviderBackoffRetries&amp;#34;&lt;/span>&lt;span style="color:#a40000">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">6&lt;/span>&lt;span style="color:#a40000">,&lt;/span>
&lt;span style="color:#4e9a06">&amp;#34;cloudProviderBackoffDuration&amp;#34;&lt;/span>&lt;span style="color:#a40000">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">5&lt;/span>&lt;span style="color:#a40000">,&lt;/span>
&lt;span style="color:#4e9a06">&amp;#34;cloudProviderRatelimit&amp;#34;&lt;/span>&lt;span style="color:#a40000">:&lt;/span> &lt;span style="color:#204a87;font-weight:bold">true&lt;/span>&lt;span style="color:#a40000">,&lt;/span>
&lt;span style="color:#4e9a06">&amp;#34;cloudProviderRateLimitQPS&amp;#34;&lt;/span>&lt;span style="color:#a40000">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">10&lt;/span>&lt;span style="color:#a40000">,&lt;/span>
&lt;span style="color:#4e9a06">&amp;#34;cloudProviderRateLimitBucket&amp;#34;&lt;/span>&lt;span style="color:#a40000">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">100&lt;/span>&lt;span style="color:#a40000">,&lt;/span>
&lt;span style="color:#4e9a06">&amp;#34;cloudProviderRatelimitQPSWrite&amp;#34;&lt;/span>&lt;span style="color:#a40000">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">10&lt;/span>&lt;span style="color:#a40000">,&lt;/span>
&lt;span style="color:#4e9a06">&amp;#34;cloudProviderRatelimitBucketWrite&amp;#34;&lt;/span>&lt;span style="color:#a40000">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">100&lt;/span>&lt;span style="color:#a40000">,&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>For v1.18.0+ refer to &lt;a href="#per-client-rate-limiting">per client rate limit config&lt;/a>&lt;/p></description></item><item><title>Docs: Component Versioning</title><link>https://nilo19.github.io/cloud-provider-azure/docs/version/component-versioning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/docs/version/component-versioning/</guid><description>
&lt;p>When syncing to a new Kubernetes release, please update corresponding lines in following files.&lt;/p>
&lt;ul>
&lt;li>&lt;del>&lt;a href="https://nilo19.github.io/cloud-provider-azure/glide.yaml">glide.yaml&lt;/a> for glide update&lt;/del>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes-sigs/cloud-provider-azure/blob/master/tests/k8s-azure/manifest/linux.json">linux.json&lt;/a> for local test deployment&lt;/li>
&lt;li>&lt;del>&lt;a href="https://nilo19.github.io/cloud-provider-azure/tests/k8s-azure/Dockerfile">Dockerfile&lt;/a> for local test image&lt;/del>&lt;/li>
&lt;/ul>
&lt;p>Please find details as following&lt;/p>
&lt;h2 id="components">Components&lt;/h2>
&lt;h3 id="1-main-package">1. Main package&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>Main dockerfile: &lt;a href="https://github.com/kubernetes-sigs/cloud-provider-azure/blob/master/Dockerfile">Dockerfile&lt;/a>&lt;/p>
&lt;p>Update golang version in &lt;code>FROM golang:*&lt;/code>&lt;/p>
&lt;p>Update &lt;code>FROM buildpack-deps:*&lt;/code> if base image version changes.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Test deployment image: &lt;a href="https://github.com/kubernetes-sigs/cloud-provider-azure/blob/master/tests/k8s-azure/manifest/linux.json">linux.json&lt;/a>&lt;/p>
&lt;p>Update &lt;code>customCcmImage&lt;/code> to latest stable released image, this is used for local deployment.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="2-kubernetes-in-e2e-test">2. Kubernetes in E2E test&lt;/h3>
&lt;p>Following Kubernetes versions should stick to Kubernetes package version specified in &lt;del>&lt;a href="https://nilo19.github.io/cloud-provider-azure/glide.yaml">glide.yaml&lt;/a>&lt;/del>, please see &lt;a href="../../dep">Dependency management&lt;/a> for details about package versions.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Test cluster hyperkube Image: &lt;a href="https://github.com/kubernetes-sigs/cloud-provider-azure/blob/master/tests/k8s-azure/manifest/linux.json">linux.json&lt;/a>&lt;/p>
&lt;p>Update &lt;code>&amp;quot;customHyperkubeImage&amp;quot;: &amp;quot;*&amp;quot;&lt;/code> for Kubernetes version.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>E2E tests: &lt;a href="https://nilo19.github.io/cloud-provider-azure/tests/k8s-azure/Dockerfile">Dockerfile&lt;/a>&lt;/p>
&lt;p>Update &lt;code>ARG K8S_VERSION=&lt;/code> for Kubernetes version.&lt;/p>
&lt;p>Update &lt;code>FROM golang:* AS build_kubernetes&lt;/code>. This should stick to the Go version used by &lt;a href="https://github.com/kubernetes/kubernetes/blob/master/build/build-image/cross/Dockerfile">Kubernetes&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="3-aks-engine-in-e2e-test">&lt;del>3. aks-engine in E2E test&lt;/del>&lt;/h3>
&lt;p>&lt;del>Edit file &lt;a href="https://nilo19.github.io/cloud-provider-azure/tests/k8s-azure/Dockerfile">Dockerfile&lt;/a>&lt;/del>&lt;/p>
&lt;p>&lt;del>Update &lt;code>ARG AKSENGINE_VERSION=&lt;/code> for aks-engine version.&lt;/del>&lt;/p>
&lt;p>&lt;del>Update &lt;code>FROM golang:* AS build_aks-engine&lt;/code>.&lt;/del>
&lt;del>This should stick to the Go version used by &lt;a href="https://github.com/Azure/aks-engine/blob/master/releases/Dockerfile.linux">aks-engine&lt;/a>.&lt;/del>&lt;/p></description></item><item><title>Docs: Dependency management</title><link>https://nilo19.github.io/cloud-provider-azure/docs/dep/dependency-management/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/docs/dep/dependency-management/</guid><description>
&lt;p>cloud-provider-azure uses &lt;a href="https://github.com/golang/go/wiki/Modules">go modules&lt;/a> for Go dependency management.&lt;/p>
&lt;h2 id="usage">Usage&lt;/h2>
&lt;p>Run &lt;a href="https://github.com/kubernetes-sigs/cloud-provider-azure/blob/master/hack/update-dependencies.sh">&lt;code>hack/update-dependencies.sh&lt;/code>&lt;/a> whenever vendored dependencies change.
This takes a minute to complete.&lt;/p>
&lt;h3 id="updating-dependencies">Updating dependencies&lt;/h3>
&lt;p>New dependencies causes golang to recompute the minor version used for each major version of each dependency. And
golang automatically removes dependencies that nothing imports any more.&lt;/p>
&lt;p>To upgrade to the latest version for all direct and indirect dependencies of the current module:&lt;/p>
&lt;ul>
&lt;li>run &lt;code>go get -u &amp;lt;package&amp;gt;&lt;/code> to use the latest minor or patch releases&lt;/li>
&lt;li>run &lt;code>go get -u=patch &amp;lt;package&amp;gt;&lt;/code> to use the latest patch releases&lt;/li>
&lt;li>run &lt;code>go get &amp;lt;package&amp;gt;@VERSION&lt;/code> to use the specified version&lt;/li>
&lt;/ul>
&lt;p>You can also manually editing &lt;code>go.mod&lt;/code> and update the versions in &lt;code>require&lt;/code> and &lt;code>replace&lt;/code> parts.&lt;/p>
&lt;p>Because of staging in Kubernetes, manually &lt;code>go.mod&lt;/code> updating is required for Kubernetes and
its staging packages. In cloud-provider-azure, their versions are set in &lt;code>replace&lt;/code> part, e.g.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#000">replace&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">...&lt;/span>
&lt;span style="color:#000">k8s&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">io&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">kubernetes&lt;/span> &lt;span style="color:#000;font-weight:bold">=&lt;/span>&lt;span style="color:#000;font-weight:bold">&amp;gt;&lt;/span> &lt;span style="color:#000">k8s&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">io&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">kubernetes&lt;/span> &lt;span style="color:#000">v0&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">.0&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">.0&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">20190815230911&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">4e7&lt;/span>&lt;span style="color:#000">fd98763aa&lt;/span>
&lt;span style="color:#000">k8s&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">io&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">legacy&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span>&lt;span style="color:#000">cloud&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span>&lt;span style="color:#000">providers&lt;/span> &lt;span style="color:#000;font-weight:bold">=&lt;/span>&lt;span style="color:#000;font-weight:bold">&amp;gt;&lt;/span> &lt;span style="color:#000">k8s&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">io&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">kubernetes&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">staging&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">src&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">k8s&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">io&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">/&lt;/span>&lt;span style="color:#000">legacy&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span>&lt;span style="color:#000">cloud&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span>&lt;span style="color:#000">providers&lt;/span> &lt;span style="color:#000">v0&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">.0&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">.0&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">20190815230911&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">4e7&lt;/span>&lt;span style="color:#000">fd98763aa&lt;/span>
&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>To update their versions, you need switch to &lt;code>$GOPATH/src/k8s.io/kubernetes&lt;/code>, checkout to
the version you want upgrade to, and finally run the following commands to get the go modules expected version:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#000">commit&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87;font-weight:bold">$(&lt;/span>&lt;span style="color:#000">TZ&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>UTC git --no-pager show --quiet --abbrev&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">12&lt;/span> --date&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;format-local:%Y%m%d%H%M%S&amp;#39;&lt;/span> --format&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;%cd-%h&amp;#34;&lt;/span>&lt;span style="color:#204a87;font-weight:bold">)&lt;/span>
&lt;span style="color:#204a87">echo&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;&lt;/span>&lt;span style="color:#4e9a06">v0.0.0-&lt;/span>&lt;span style="color:#000">$commit&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>After this, replace all kubernetes and staging versions (e.g. &lt;code>v0.0.0-20190815230911-4e7fd98763aa&lt;/code> in above example) in &lt;code>go.mod&lt;/code>.&lt;/p>
&lt;p>Always run &lt;code>hack/update-dependencies.sh&lt;/code> after changing &lt;code>go.mod&lt;/code> by any of these methods (or adding new imports).&lt;/p>
&lt;p>See golang's &lt;a href="https://github.com/golang/go/wiki/Modules#gomod">go.mod&lt;/a>, &lt;a href="https://blog.golang.org/using-go-modules">Using Go Modules&lt;/a> and &lt;a href="https://github.com/kubernetes/enhancements/blob/master/keps/sig-architecture/2019-03-19-go-modules.md">Kubernetes Go modules&lt;/a> docs for more details.&lt;/p></description></item><item><title>Contribute: Issues and pull requests migration</title><link>https://nilo19.github.io/cloud-provider-azure/contribute/issues-and-pull-requests-migration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/contribute/issues-and-pull-requests-migration/</guid><description>
&lt;p>&lt;em>NOTE&lt;/em> This page only applies after Azure cloud provider implementation code has been moved to this repository.&lt;/p>
&lt;p>There are some ongoing issues and pull requests addressing the Azure cloud provider in Kubernetes repository.&lt;/p>
&lt;p>When we turned to use the standalone cloud provider in this repository, those issues and pull requests should also be moved.&lt;/p>
&lt;p>Here are some notes for issues and pull requests migration.&lt;/p>
&lt;h2 id="issue-migration">Issue migration&lt;/h2>
&lt;p>If issue applies only to Azure cloud provider, please close it and create a new one in this repository.&lt;/p>
&lt;p>If issue also involves other component, leave it there, but do create a new issue in this repository to track counterpater in Azure cloud provider.&lt;/p>
&lt;p>In both cases, leave a link to the new created issue in the old issue.&lt;/p>
&lt;h2 id="pull-request-migration">Pull request migration&lt;/h2>
&lt;p>Basically we are migrating code from &lt;code>k8s.io/legacy-cloud-providers/azure/&lt;/code> to &lt;code>github.com/kubernetes-sigs/cloud-provider-azure/cloud-controller-manager/azureprovider&lt;/code>.&lt;/p>
&lt;p>The following steps describe how to port an existing PR from kubernetes repository to this repository.&lt;/p>
&lt;ol>
&lt;li>Generate pull request patch&lt;/li>
&lt;/ol>
&lt;p>In your kubernetes repository, run following to generate a patch for your PR.&lt;/p>
&lt;ul>
&lt;li>PR_ID: Pull Request ID in kubernetes repository&lt;/li>
&lt;li>UPSTREAM_BRANCH: Branch name pointing to upstream, basically the branch with url &lt;code>https://github.com/kubernetes/kubernetes.git&lt;/code> or &lt;code>https://k8s.io/kubernetes&lt;/code>&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>PR_ID=
UPSTREAM_BRANCH=origin
PR_BRANCH_LOCAL=PR$PR_ID
git fetch $UPSTREAM_BRANCH pull/$PR_ID/head:$PR_BRANCH_LOCAL
MERGE_BASE=$(git merge-base $UPSTREAM_BRANCH/master $PR_BRANCH_LOCAL)
PATCH_FILE=/tmp/${PR_ID}.patch
git diff $MERGE_BASE $PR_BRANCH_LOCAL &amp;gt; $PATCH_FILE
git branch -D $PR_BRANCH_LOCAL
&lt;/code>&lt;/pre>&lt;ol start="2">
&lt;li>Transform the patch and apply&lt;/li>
&lt;/ol>
&lt;p>Switch to kubernetes-azure-cloud-controller-manager repo.
Apply the patch:&lt;/p>
&lt;pre>&lt;code>hack/transform-patch.pl $PATCH_FILE | git apply
&lt;/code>&lt;/pre>&lt;p>If any of file in the patch does not fall under Azure cloud provider directory, the transform script will prompt a warning.&lt;/p></description></item><item><title>Docs: Release Versioning</title><link>https://nilo19.github.io/cloud-provider-azure/docs/release/release-versioning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/docs/release/release-versioning/</guid><description>
&lt;h2 id="release-source">Release source&lt;/h2>
&lt;p>There're two major code change sources for this project, either may push forward a new release for &lt;code>Kubernetes azure-cloud-controller-manager&lt;/code>:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Changes in &lt;a href="https://kubernetes.io/docs/concepts/overview/components/#cloud-controller-manager">Kubernetes cloud-controller-manager&lt;/a>, which happens in &lt;a href="https://github.com/kubernetes/kubernetes">Kubernetes repository&lt;/a>
Since this project dependes on &lt;code>Kubernetes cloud-controller-manager&lt;/code>, we'll periodically sync changes from Kubernetes upstream repository. When upstream shipped a new release tag, we may consider publishing a new release&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Changes in &lt;a href="../cloud-controller-manager/azureprovider">Azure cloud provider&lt;/a>, which happens directly in this repository
Azure cloud provider also accepts new features and bug changes. In cases when a security fix is required or when the changes accumulated to certain amount, we may also consider publishing a new release, even if there is no change from Kubernetes upstream.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="versioning">Versioning&lt;/h2>
&lt;p>This project is a Kubernetes component whereas the functionalities and APIs all go with Kubernetes upstream project, thus we will use same versioning mechanism of Kubernetes, with some subtle differences for &lt;code>Azure cloud provider&lt;/code> and non-Kubernetes changes.&lt;/p>
&lt;p>The basic rule is:&lt;/p>
&lt;ol>
&lt;li>Every release version follows &lt;code>Semantic Versioning&lt;/code>, in the form of &lt;code>MAJOR.MINOR.PATCH&lt;/code>&lt;/li>
&lt;li>For &lt;code>MAJOR.MINOR&lt;/code>, it keeps same value as the Kubernetes upstream&lt;/li>
&lt;li>For &lt;code>PATCH&lt;/code>, it is calculated independently:
&lt;ul>
&lt;li>If upstream Kubernetes has a new a &lt;a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/release/versioning.md#patch-releases">patch release&lt;/a>, which introduces change in &lt;code>cloud-controller-manager&lt;/code> or any component we depend on, then sync the change and increase the &lt;code>PATCH&lt;/code> number.&lt;/li>
&lt;li>If any code change happens in &lt;a href="../cloud-controller-manager/azureprovider">Azure cloud provider&lt;/a> or other dependency projects, which becomes eligible for a new release, then increase the &lt;code>PATCH&lt;/code> number.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>References:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/release/versioning.md">Kubernetes Release Versioning&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://semver.org/">Semantic Versioning&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="branch-and-version-scheme">Branch and version scheme&lt;/h3>
&lt;p>This project uses golang's vendoring mechanism for managing dependencies (see &lt;a href="docs/dependency-management.md">Dependency management&lt;/a> for detail). When talking about &amp;lsquo;sync from Kubernetes upstream&amp;rsquo;, it actually means vendoring Kubernetes repository code under the vendor directory.&lt;/p>
&lt;p>During each sync from upstream, it is usually fine to sync to latest commit. But if there is a new tagged commit in upstream that we haven't vendored, we should sync to that tagged commit first, and apply a version tag correspondingly if applicable. The version tag mechanism is a bit different on master branch and releasing branch, please see below for detail.&lt;/p>
&lt;p>The upstream syncing change should be made in a single Pull Request. If in some case, the upstream change causes a test break, then the pull requests should not be merged until follow up fix commits are added.&lt;/p>
&lt;p>For example, if upstream change adds a new cloud provider interface, syncing the upstream change may raise a test break, and we should add the implementation (even no-op) in same pull request.&lt;/p>
&lt;h4 id="master-branch">master branch&lt;/h4>
&lt;p>This is the main development branch for merging pull requests. When upgrading dependencies, it will sync from Kubernetes upstream's &lt;code>master&lt;/code> branch.&lt;/p>
&lt;p>Fixes to releasing branches should be merged in master branch first, and then ported to corresponding release branch.&lt;/p>
&lt;p>Version tags:&lt;/p>
&lt;ul>
&lt;li>X.Y.0-alpha.0
&lt;ul>
&lt;li>This is initial tag for a new release, it will be applied when a release branch is created. See below for detail&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>X.Y.0-alpha.W, W &amp;gt; 0
&lt;ul>
&lt;li>Those version tags are periodically created if enough change accumulated. It does not have direct mapping with &lt;code>X.Y.0-alpha.W&lt;/code> in Kubernetes upstream&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="releasing-branch">releasing branch&lt;/h4>
&lt;p>For release &lt;code>X.Y&lt;/code>, the branch will have name &lt;code>release-X.Y&lt;/code>. When upgrading dependencies, it will sync with Kubernetes upstream's &lt;code>release-X.Y&lt;/code> branch.
Release branch would be created when upstream release branch is created and first &lt;code>X.Y.0-beta.0&lt;/code> tag is applied.&lt;/p>
&lt;p>Version tags:&lt;/p>
&lt;ul>
&lt;li>X.Y.0-beta.0
&lt;ul>
&lt;li>&lt;code>X.Y.0-beta.0&lt;/code> would be tagged at first independent commit on release branch, the corresponding separation point commit on master would be tagged &lt;code>X.Y+1.0-alpha.0&lt;/code>&lt;/li>
&lt;li>No new feature changes are allowed from this time on&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>X.Y.0-beta.W, W &amp;gt; 0
&lt;ul>
&lt;li>Those version tags are periodically created if enough change accumulated. It does not have direct mapping with &lt;code>X.Y.0-beta.W&lt;/code> in Kubernetes upstream&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>X.Y.0
&lt;ul>
&lt;li>This is the final release version. When upstream &lt;code>X.Y.0&lt;/code> tag rolls out, we will begin prepare &lt;code>X.Y.0&lt;/code> release&lt;/li>
&lt;li>After merging upstream &lt;code>X.Y.0&lt;/code> tag commit, we will run full test cycle to ensure the &lt;code>Azure cloud provider&lt;/code> works well before release:
&lt;ul>
&lt;li>If any test fails, prepare fixes first. If the fix also applies to master branch, then also apply it to master.&lt;/li>
&lt;li>Rerun full test cycle till all tests got passed stablely&lt;/li>
&lt;li>Finally, apply &lt;code>X.Y.0&lt;/code> to latest commit of releasing branch&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>X.Y.1-beta.0 will be tagged at the same commit&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>X.Y.Z, Z &amp;gt; 0
&lt;ul>
&lt;li>Those version tags are periodically created if enough change accumulated. It does not have direct mapping with &lt;code>X.Y.Z&lt;/code> in Kubernetes upstream&lt;/li>
&lt;li>Testing and release process follows same rule as &lt;code>X.Y.0&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="ci-and-dev-version-scheme">CI and dev version scheme&lt;/h3>
&lt;p>We use &lt;a href="https://git-scm.com/docs/git-describe">git-describe&lt;/a> as versioning source, please check &lt;a href="../cloud-controller-manager/version">version&lt;/a> for detail.&lt;/p>
&lt;p>In this case, for commits that does not have a certain tag, the result version would be something like &amp;lsquo;v0.1.0-alpha.0-25-gd7999d10&amp;rsquo;.&lt;/p></description></item><item><title>Docs: How to Use Availability Zones</title><link>https://nilo19.github.io/cloud-provider-azure/docs/howto/using-availability-zones/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/docs/howto/using-availability-zones/</guid><description>
&lt;p>&lt;strong>Feature Status:&lt;/strong> Alpha since v1.12.&lt;/p>
&lt;p>Kubernetes v1.12 adds support for &lt;a href="https://azure.microsoft.com/en-us/global-infrastructure/availability-zones/">Azure availability zones (AZ)&lt;/a>. Nodes in availability zone will be added with label &lt;code>failure-domain.beta.kubernetes.io/zone=&amp;lt;region&amp;gt;-&amp;lt;AZ&amp;gt;&lt;/code> and topology-aware provisioning is added for Azure managed disks storage class.&lt;/p>
&lt;p>&lt;strong>TOC:&lt;/strong>&lt;/p>
&lt;!-- TOC -->
&lt;ul>
&lt;li>&lt;a href="#availability-zones">Availability Zones&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#pre-requirements">Pre-requirements&lt;/a>&lt;/li>
&lt;li>&lt;a href="#node-labels">Node labels&lt;/a>&lt;/li>
&lt;li>&lt;a href="#load-balancer">Load Balancer&lt;/a>&lt;/li>
&lt;li>&lt;a href="#managed-disks">Managed Disks&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#storageclass-examples">StorageClass examples&lt;/a>&lt;/li>
&lt;li>&lt;a href="#pv-examples">PV examples&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#appendix">Appendix&lt;/a>&lt;/li>
&lt;li>&lt;a href="#reference">Reference&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;!-- /TOC -->
&lt;h2 id="pre-requirements">Pre-requirements&lt;/h2>
&lt;p>Because only standard load balancer is supported with AZ, it is a prerequisite to enable AZ for the cluster. It should be configured in Azure cloud provider configure file (e.g. &lt;code>/etc/kubernetes/azure.json&lt;/code>):&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;loadBalancerSku&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;standard&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#a40000">.&lt;/span>&lt;span style="color:#a40000">.&lt;/span>&lt;span style="color:#a40000">.&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>If topology-aware provisioning feature is used, feature gate &lt;code>VolumeScheduling&lt;/code> should be enabled on master components (e.g. kube-apiserver, kube-controller-manager and kube-scheduler).&lt;/p>
&lt;h2 id="node-labels">Node labels&lt;/h2>
&lt;p>Both zoned and unzoned nodes are supported, but the value of node label &lt;code>failure-domain.beta.kubernetes.io/zone&lt;/code> are different:&lt;/p>
&lt;ul>
&lt;li>For zoned nodes, the value is &lt;code>&amp;lt;region&amp;gt;-&amp;lt;AZ&amp;gt;&lt;/code>, e.g. &lt;code>centralus-1&lt;/code>.&lt;/li>
&lt;li>For unzoned nodes, the value is faultDomain, e.g. &lt;code>0&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>e.g.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">$&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kubectl&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>get&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>nodes&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>--show-labels&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>NAME&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>STATUS&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>AGE&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>VERSION&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>LABELS&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>kubernetes-node12&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>Ready&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>6m&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>v1&lt;span style="color:#0000cf;font-weight:bold">.11&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>failure-domain.beta.kubernetes.io/region=centralus&lt;span style="color:#000;font-weight:bold">,&lt;/span>failure-domain.beta.kubernetes.io/zone=centralus&lt;span style="color:#0000cf;font-weight:bold">-1&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>...&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="load-balancer">Load Balancer&lt;/h2>
&lt;p>&lt;code>loadBalancerSku&lt;/code> has been set to &lt;code>standard&lt;/code> in cloud provider configure file, so standard load balancer and standard public IPs will be provisioned automatically for services with type &lt;code>LoadBalancer&lt;/code>. Both load balancer and public IPs are zone redundant.&lt;/p>
&lt;h2 id="managed-disks">Managed Disks&lt;/h2>
&lt;p>Zone-aware and topology-aware provisioning are supported for Azure managed disks. To support these features, a few options are added in AzureDisk storage class:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>zoned&lt;/strong>: indicates whether new disks are provisioned with AZ. Default is true.&lt;/li>
&lt;li>&lt;strong>allowedTopologies&lt;/strong>: indicates which topologies are allowed for topology-aware provisioning. Only can be set if &lt;code>zoned&lt;/code> is not false.&lt;/li>
&lt;/ul>
&lt;h3 id="storageclass-examples">StorageClass examples&lt;/h3>
&lt;p>An example of zone-aware provisioning storage class is:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">apiVersion&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>storage.k8s.io/v1&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>kind&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>StorageClass&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>metadata&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>annotations&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>labels&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kubernetes.io/cluster-service&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#4e9a06">&amp;#34;true&amp;#34;&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>name&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>managed-premium&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>parameters&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kind&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>Managed&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>storageaccounttype&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>Premium_LRS&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>zoned&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#4e9a06">&amp;#34;true&amp;#34;&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>provisioner&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kubernetes.io/azure-disk&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>volumeBindingMode&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>WaitForFirstConsumer&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Another example of topology-aware provisioning storage class is:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">apiVersion&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>storage.k8s.io/v1&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>kind&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>StorageClass&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>metadata&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>annotations&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>labels&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kubernetes.io/cluster-service&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#4e9a06">&amp;#34;true&amp;#34;&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>name&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>managed-premium&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>parameters&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kind&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>Managed&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>storageaccounttype&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>Premium_LRS&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>provisioner&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kubernetes.io/azure-disk&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>volumeBindingMode&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>WaitForFirstConsumer&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>allowedTopologies&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>-&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>matchLabelExpressions&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>-&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>key&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>failure-domain.beta.kubernetes.io/zone&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>values&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>-&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>centralus&lt;span style="color:#0000cf;font-weight:bold">-1&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>-&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>centralus&lt;span style="color:#0000cf;font-weight:bold">-2&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="pv-examples">PV examples&lt;/h3>
&lt;p>When feature gate &lt;code>VolumeScheduling&lt;/code> disabled, no &lt;code>NodeAffinity&lt;/code> set for zoned PV:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ kubectl describe pv
Name: pvc-d30dad05-9ad8-11e8-94f2-000d3a07de8c
Labels: failure-domain.beta.kubernetes.io/region&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>southeastasia
failure-domain.beta.kubernetes.io/zone&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>southeastasia-2
Annotations: pv.kubernetes.io/bound-by-controller&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>yes
pv.kubernetes.io/provisioned-by&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>kubernetes.io/azure-disk
volumehelper.VolumeDynamicallyCreatedByKey&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>azure-disk-dynamic-provisioner
Finalizers: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>kubernetes.io/pv-protection&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
StorageClass: default
Status: Bound
Claim: default/pvc-azuredisk
Reclaim Policy: Delete
Access Modes: RWO
Capacity: 5Gi
Node Affinity:
Required Terms:
Term 0: failure-domain.beta.kubernetes.io/region in &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>southeastasia&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
failure-domain.beta.kubernetes.io/zone in &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>southeastasia-2&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
Message:
Source:
Type: AzureDisk &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>an Azure Data Disk mount on the host and &lt;span style="color:#204a87">bind&lt;/span> mount to the pod&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
DiskName: k8s-5b3d7b8f-dynamic-pvc-d30dad05-9ad8-11e8-94f2-000d3a07de8c
DiskURI: /subscriptions/&amp;lt;subscription-id&amp;gt;/resourceGroups/&amp;lt;rg-name&amp;gt;/providers/Microsoft.Compute/disks/k8s-5b3d7b8f-dynamic-pvc-d30dad05-9ad8-11e8-94f2-000d3a07de8c
Kind: Managed
FSType:
CachingMode: None
ReadOnly: &lt;span style="color:#204a87">false&lt;/span>
Events: &amp;lt;none&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>When feature gate &lt;code>VolumeScheduling&lt;/code> enabled, &lt;code>NodeAffinity&lt;/code> will be populated for zoned PV:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ kubectl describe pv
Name: pvc-0284337b-9ada-11e8-a7f6-000d3a07de8c
Labels: failure-domain.beta.kubernetes.io/region&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>southeastasia
failure-domain.beta.kubernetes.io/zone&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>southeastasia-2
Annotations: pv.kubernetes.io/bound-by-controller&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>yes
pv.kubernetes.io/provisioned-by&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>kubernetes.io/azure-disk
volumehelper.VolumeDynamicallyCreatedByKey&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>azure-disk-dynamic-provisioner
Finalizers: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>kubernetes.io/pv-protection&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
StorageClass: default
Status: Bound
Claim: default/pvc-azuredisk
Reclaim Policy: Delete
Access Modes: RWO
Capacity: 5Gi
Node Affinity:
Required Terms:
Term 0: failure-domain.beta.kubernetes.io/region in &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>southeastasia&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
failure-domain.beta.kubernetes.io/zone in &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>southeastasia-2&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
Message:
Source:
Type: AzureDisk &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>an Azure Data Disk mount on the host and &lt;span style="color:#204a87">bind&lt;/span> mount to the pod&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
DiskName: k8s-5b3d7b8f-dynamic-pvc-0284337b-9ada-11e8-a7f6-000d3a07de8c
DiskURI: /subscriptions/&amp;lt;subscription-id&amp;gt;/resourceGroups/&amp;lt;rg-name&amp;gt;/providers/Microsoft.Compute/disks/k8s-5b3d7b8f-dynamic-pvc-0284337b-9ada-11e8-a7f6-000d3a07de8c
Kind: Managed
FSType:
CachingMode: None
ReadOnly: &lt;span style="color:#204a87">false&lt;/span>
Events: &amp;lt;none&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>While unzoned disks are not able to attach in zoned nodes, &lt;code>NodeAffinity&lt;/code> will also be set for them so that they will only be scheduled to unzoned nodes:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ kubectl describe pv pvc-bdf93a67-9c45-11e8-ba6f-000d3a07de8c
Name: pvc-bdf93a67-9c45-11e8-ba6f-000d3a07de8c
Labels: &amp;lt;none&amp;gt;
Annotations: pv.kubernetes.io/bound-by-controller&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>yes
pv.kubernetes.io/provisioned-by&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>kubernetes.io/azure-disk
volumehelper.VolumeDynamicallyCreatedByKey&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>azure-disk-dynamic-provisioner
Finalizers: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>kubernetes.io/pv-protection&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
StorageClass: azuredisk-unzoned
Status: Bound
Claim: default/unzoned-pvc
Reclaim Policy: Delete
Access Modes: RWO
Capacity: 5Gi
Node Affinity:
Required Terms:
Term 0: failure-domain.beta.kubernetes.io/region in &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>southeastasia&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
failure-domain.beta.kubernetes.io/zone in &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>0&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
Term 1: failure-domain.beta.kubernetes.io/region in &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>southeastasia&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
failure-domain.beta.kubernetes.io/zone in &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>1&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
Term 2: failure-domain.beta.kubernetes.io/region in &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>southeastasia&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
failure-domain.beta.kubernetes.io/zone in &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>2&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
Message:
Source:
Type: AzureDisk &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>an Azure Data Disk mount on the host and &lt;span style="color:#204a87">bind&lt;/span> mount to the pod&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
DiskName: k8s-5b3d7b8f-dynamic-pvc-bdf93a67-9c45-11e8-ba6f-000d3a07de8c
DiskURI: /subscriptions/&amp;lt;subscription&amp;gt;/resourceGroups/&amp;lt;rg-name&amp;gt;/providers/Microsoft.Compute/disks/k8s-5b3d7b8f-dynamic-pvc-bdf93a67-9c45-11e8-ba6f-000d3a07de8c
Kind: Managed
FSType:
CachingMode: None
ReadOnly: &lt;span style="color:#204a87">false&lt;/span>
Events: &amp;lt;none&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="appendix">Appendix&lt;/h2>
&lt;p>Note that unlike most cases, fault domain and availability zones mean different on Azure:&lt;/p>
&lt;ul>
&lt;li>A Fault Domain (FD) is essentially a rack of servers. It consumes subsystems like network, power, cooling etc.&lt;/li>
&lt;li>Availability Zones are unique physical locations within an Azure region. Each zone is made up of one or more data centers equipped with independent power, cooling, and networking.&lt;/li>
&lt;/ul>
&lt;p>An Availability Zone in an Azure region is a combination of a fault domain and an update domain (Same like FD, but for updates. When upgrading a deployment, it is carried out one update domain at a time). For example, if you create three or more VMs across three zones in an Azure region, your VMs are effectively distributed across three fault domains and three update domains.&lt;/p>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;p>See design docs for AZ in &lt;a href="https://github.com/kubernetes/enhancements/blob/master/keps/sig-cloud-provider/azure/20180711-azure-availability-zones.md">KEP for Azure availability zones&lt;/a>.&lt;/p></description></item><item><title>Docs: Azure E2E tests</title><link>https://nilo19.github.io/cloud-provider-azure/docs/e2e/e2e-tests-azure/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/docs/e2e/e2e-tests-azure/</guid><description>
&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>Here provides some E2E tests only specific to Azure provider.&lt;/p>
&lt;h2 id="prerequisite">Prerequisite&lt;/h2>
&lt;h3 id="deploy-a-kubernetes-cluster-with-azure-ccm">Deploy a Kubernetes cluster with Azure CCM&lt;/h3>
&lt;p>Refer step 1-3 in &lt;a href="../e2e-tests">e2e-tests&lt;/a> for deploying the Kubernetes cluster.&lt;/p>
&lt;h3 id="setup-azure-credentials">Setup Azure credentials&lt;/h3>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">K8S_AZURE_TENANTID&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;tenant-id&amp;gt; &lt;span style="color:#8f5902;font-style:italic"># the tenant ID&lt;/span>
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">K8S_AZURE_SUBSID&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;subscription-id&amp;gt; &lt;span style="color:#8f5902;font-style:italic"># the subscription ID&lt;/span>
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">K8S_AZURE_SPID&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;service-principal-id&amp;gt; &lt;span style="color:#8f5902;font-style:italic"># the service principal ID&lt;/span>
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">K8S_AZURE_SPSEC&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;service-principal-secret&amp;gt; &lt;span style="color:#8f5902;font-style:italic"># the service principal secret&lt;/span>
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">K8S_AZURE_ENVIRONMENT&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;AzurePublicCloud&amp;gt; &lt;span style="color:#8f5902;font-style:italic"># the cloud environment (optional, default is AzurePublicCloud)&lt;/span>
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">K8S_AZURE_LOCATION&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;location&amp;gt; &lt;span style="color:#8f5902;font-style:italic"># the location&lt;/span>
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">K8S_AZURE_LOADBALANCE_SKU&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;loadbalancer-sku&amp;gt; &lt;span style="color:#8f5902;font-style:italic"># the sku of load balancer (optional, default is basic)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="setup-kubeconfig">Setup KUBECONFIG&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>Locate your kubeconfig and set it as env variable
&lt;code>export KUBECONFIG=&amp;lt;kubeconfig&amp;gt;&lt;/code>
or
&lt;code>cp &amp;lt;kubeconfig&amp;gt; ~/.kube/config&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Test it via &lt;code>kubectl version&lt;/code>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="run-test">Run Test&lt;/h2>
&lt;h3 id="have-installed-ginkgo">Have installed ginkgo&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>Run &lt;code>ginkgo ./tests/e2e/ &lt;/code>&lt;/p>
&lt;p>For more usage of ginkgo, please follow &lt;a href="https://github.com/onsi/ginkgo/blob/master/README.md">ginkgo&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="without-ginkgo">Without ginkgo&lt;/h3>
&lt;ul>
&lt;li>Run &lt;code>go test ./tests/e2e/ -timeout 0&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>After a long time test, a JUnit report will be generated in a directory named by the cluster name&lt;/p></description></item><item><title>Docs: How to Deploy Cross Resource Group Nodes</title><link>https://nilo19.github.io/cloud-provider-azure/docs/howto/using-cross-resource-group-nodes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/docs/howto/using-cross-resource-group-nodes/</guid><description>
&lt;p>&lt;strong>Feature status:&lt;/strong> Alpha since v1.12.&lt;/p>
&lt;p>Kubernetes v1.12 adds support for cross resource group (RG) nodes and unmanaged (such as on-prem) nodes in Azure cloud provider. A few assumptions are made for such nodes:&lt;/p>
&lt;ul>
&lt;li>Cross-RG nodes are in same region and set with required labels (as clarified in the following part)&lt;/li>
&lt;li>Nodes will not be part of the load balancer managed by cloud provider&lt;/li>
&lt;li>Both node and container networking should be configured properly by provisioning tools&lt;/li>
&lt;li>AzureDisk is supported for Azure cross-RG nodes, but not for on-prem nodes&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>TOC:&lt;/strong>&lt;/p>
&lt;!-- TOC -->
&lt;ul>
&lt;li>&lt;a href="#cross-resource-group-nodes">Cross resource group nodes&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#pre-requirements">Pre-requirements&lt;/a>&lt;/li>
&lt;li>&lt;a href="#cross-rg-nodes">Cross-RG nodes&lt;/a>&lt;/li>
&lt;li>&lt;a href="#unmanaged-nodes">Unmanaged nodes&lt;/a>&lt;/li>
&lt;li>&lt;a href="#reference">Reference&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;!-- /TOC -->
&lt;h2 id="pre-requirements">Pre-requirements&lt;/h2>
&lt;p>Because cross-RG nodes and unmanaged nodes won't be added to Azure load balancer backends, feature gate &lt;code>ServiceNodeExclusion&lt;/code> should be enabled for master components (e.g. kube-controller-manager).&lt;/p>
&lt;h2 id="cross-rg-nodes">Cross-RG nodes&lt;/h2>
&lt;p>Cross-RG nodes should register themselves with required labels together with cloud provider:&lt;/p>
&lt;ul>
&lt;li>&lt;code>node.kubernetes.io/exclude-balancer&lt;/code>, which is used to exclude the node from load balancer.
&lt;ul>
&lt;li>&lt;code>alpha.service-controller.kubernetes.io/exclude-balancer=true&lt;/code> should be used if the cluster version is below v1.16.0.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>kubernetes.azure.com/resource-group=&amp;lt;rg-name&amp;gt;&lt;/code>, which provides external RG and is used to get node information.&lt;/li>
&lt;li>cloud provider config
&lt;ul>
&lt;li>&lt;code>--cloud-provider=azure&lt;/code> when using kube-controller-manager&lt;/li>
&lt;li>&lt;code>--cloud-provider=external&lt;/code> when using cloud-controller-manager&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>For example,&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">kubelet ... &lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> --cloud-provider&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>azure &lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> --cloud-config&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>/etc/kubernetes/azure.json &lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> --node-labels&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>node.kubernetes.io/exclude-balancer&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>true,kubernetes.azure.com/resource-group&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;rg-name&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="unmanaged-nodes">Unmanaged nodes&lt;/h2>
&lt;p>On-prem nodes are different from Azure nodes, all Azure coupled features (such as load balancers and Azure managed disks) are not supported for them. To prevent the node being deleted, Azure cloud provider will always assumes the node existing.&lt;/p>
&lt;p>On-prem nodes should register themselves with labels &lt;code>node.kubernetes.io/exclude-balancer=true&lt;/code> and &lt;code>kubernetes.azure.com/managed=false&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>node.kubernetes.io/exclude-balancer=true&lt;/code>, which is used to exclude the node from load balancer.&lt;/li>
&lt;li>&lt;code>kubernetes.azure.com/managed=false&lt;/code>, which indicates the node is on-prem or on other clouds.&lt;/li>
&lt;/ul>
&lt;p>For example,&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">kubelet ...&lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> --cloud-provider&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> --node-labels&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>node.kubernetes.io/exclude-balancer&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>true,kubernetes.azure.com/managed&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87">false&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="reference">Reference&lt;/h2>
&lt;p>See design docs for cross resource group nodes in &lt;a href="https://github.com/kubernetes/enhancements/blob/master/keps/sig-cloud-provider/azure/20180809-cross-resource-group-nodes.md">KEP 20180809-cross-resource-group-nodes&lt;/a>.&lt;/p></description></item><item><title>Docs: Azure Disk Plugin Known Issues</title><link>https://nilo19.github.io/cloud-provider-azure/docs/persistentvolumes/azuredisk/issues/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/docs/persistentvolumes/azuredisk/issues/</guid><description>
&lt;!-- TOC -->
&lt;ul>
&lt;li>&lt;a href="#azure-disk-plugin-known-issues">azure disk plugin known issues&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#recommended-stable-version-for-azure-disk">Recommended stable version for azure disk&lt;/a>&lt;/li>
&lt;li>&lt;a href="#1-disk-attach-error">1. disk attach error&lt;/a>&lt;/li>
&lt;li>&lt;a href="#2-disk-unavailable-after-attachdetach-a-data-disk-on-a-node">2. disk unavailable after attach/detach a data disk on a node&lt;/a>&lt;/li>
&lt;li>&lt;a href="#3-azure-disk-support-on-sovereign-cloud">3. Azure disk support on Sovereign Cloud&lt;/a>&lt;/li>
&lt;li>&lt;a href="#4-time-cost-for-azure-disk-pvc-mount">4. Time cost for Azure Disk PVC mount&lt;/a>&lt;/li>
&lt;li>&lt;a href="#5-azure-disk-pvc-multi-attach-error-makes-disk-mount-very-slow-or-mount-failure-forever">5. Azure disk PVC &lt;code>Multi-Attach error&lt;/code>, makes disk mount very slow or mount failure forever&lt;/a>&lt;/li>
&lt;li>&lt;a href="#6-waitforattach-failed-for-azure-disk-parsing-devdiskazurescsi1lun1-invalid-syntax">6. WaitForAttach failed for azure disk: parsing &amp;ldquo;/dev/disk/azure/scsi1/lun1&amp;rdquo;: invalid syntax&lt;/a>&lt;/li>
&lt;li>&lt;a href="#7-uid-and-gid-setting-in-azure-disk">7. &lt;code>uid&lt;/code> and &lt;code>gid&lt;/code> setting in azure disk&lt;/a>&lt;/li>
&lt;li>&lt;a href="#8-addition-of-a-blob-based-disk-to-vm-with-managed-disks-is-not-supported">8. &lt;code>Addition of a blob based disk to VM with managed disks is not supported&lt;/code>&lt;/a>&lt;/li>
&lt;li>&lt;a href="#9-dynamic-azure-disk-pvc-try-to-access-wrong-storage-account-of-other-resource-group">9. dynamic azure disk PVC try to access wrong storage account (of other resource group)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#10-data-loss-if-using-existing-azure-disk-with-partitions-in-disk-mount">10. data loss if using existing azure disk with partitions in disk mount&lt;/a>&lt;/li>
&lt;li>&lt;a href="#11-delete-azure-disk-pvc-which-is-already-in-use-by-a-pod">11. Delete azure disk PVC which is already in use by a pod&lt;/a>&lt;/li>
&lt;li>&lt;a href="#12-create-azure-disk-pvc-failed-due-to-account-creation-failure">12. create azure disk PVC failed due to account creation failure&lt;/a>&lt;/li>
&lt;li>&lt;a href="#13-cannot-find-Lun-for-disk">13. cannot find Lun for disk&lt;/a>&lt;/li>
&lt;li>&lt;a href="#14-azure-disk-attachdetach-failure-mount-issue-io-error">14. azure disk attach/detach failure, mount issue, i/o error&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;!-- /TOC -->
&lt;h2 id="recommended-stable-version-for-azure-disk">Recommended stable version for azure disk&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>stable version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>1.7.14 or later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.13 or later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.7 or later (1.9.6 on AKS)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.12 or later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>1.11.6 or later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>1.12.4 or later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>1.13.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="1-disk-attach-error">1. disk attach error&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>In some corner case(detaching multiple disks on a node simultaneously), when scheduling a pod with azure disk mount from one node to another, there could be lots of disk attach error(no recovery) due to the disk not being released in time from the previous node. This issue is due to lack of lock before DetachDisk operation, actually there should be a central lock for both AttachDisk and DetachDisk operations, only one AttachDisk or DetachDisk operation is allowed at one time.&lt;/p>
&lt;p>The disk attach error could be like following:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">Cannot attach data disk &lt;span style="color:#4e9a06">&amp;#39;cdb-dynamic-pvc-92972088-11b9-11e8-888f-000d3a018174&amp;#39;&lt;/span> to VM &lt;span style="color:#4e9a06">&amp;#39;kn-edge-0&amp;#39;&lt;/span> because the disk is currently being detached or the last detach operation failed. Please &lt;span style="color:#204a87">wait&lt;/span> &lt;span style="color:#204a87;font-weight:bold">until&lt;/span> the disk is completely detached and &lt;span style="color:#204a87;font-weight:bold">then&lt;/span> try again or delete/detach the disk explicitly again.
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/60101">Azure Disk Detach are not working with multiple disk detach on the same Node&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/46421">Azure disk fails to attach and mount, causing rescheduled pod to stall following node disruption&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/acs-engine/issues/2002">Since Intel CPU Azure update, new Azure Disks are not mounting, very critical&amp;hellip; &lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/ACS/issues/12">Busy azure-disk regularly fail to mount causing K8S Pod deployments to halt&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Mitigation&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>option#1: Update every agent node that has attached or detached the disk in problem&lt;/li>
&lt;/ul>
&lt;p>In Azure cloud shell, run&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#000">$vm&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> Get-AzureRMVM -ResourceGroupName &lt;span style="color:#000">$rg&lt;/span> -Name &lt;span style="color:#000">$vmname&lt;/span>
Update-AzureRmVM -ResourceGroupName &lt;span style="color:#000">$rg&lt;/span> -VM &lt;span style="color:#000">$vm&lt;/span> -verbose -debug
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In Azure cli, run&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">az vm update -g &amp;lt;group&amp;gt; -n &amp;lt;name&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>option#2:&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>&lt;code>kubectl cordon node&lt;/code> #make sure no scheduling on this node&lt;/li>
&lt;li>&lt;code>kubectl drain node&lt;/code> #schedule pod in current node to other node&lt;/li>
&lt;li>restart the Azure VM for node via the API or portal, wait until VM is &amp;ldquo;Running&amp;rdquo;&lt;/li>
&lt;li>&lt;code>kubectl uncordon node&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/60183">fix race condition issue when detaching azure disk&lt;/a> has fixed this issue by add a lock before DetachDisk&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.6&lt;/td>
&lt;td>no fix since v1.6 does not accept any cherry-pick&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>1.7.14&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="2-disk-unavailable-after-attachdetach-a-data-disk-on-a-node">2. disk unavailable after attach/detach a data disk on a node&lt;/h2>
&lt;blockquote>
&lt;p>💡 NOTE: Azure platform has fixed the host cache issue, the suggested host cache setting of data disk is &lt;code>ReadOnly&lt;/code> now, more details about &lt;a href="https://docs.microsoft.com/en-us/azure/virtual-machines/windows/premium-storage-performance#disk-caching">azure disk cache setting&lt;/a>
&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;/blockquote>
&lt;p>From k8s v1.7, default host cache setting changed from &lt;code>None&lt;/code> to &lt;code>ReadWrite&lt;/code>, this change would lead to device name change after attach multiple disks on a node, finally lead to disk unavailable from pod. When access data disk inside a pod, will get following error:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>root@admin-0 /&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>&lt;span style="color:#8f5902;font-style:italic"># ls /datadisk&lt;/span>
ls: reading directory .: Input/output error
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In my testing on Ubuntu 16.04 D2_V2 VM, when attaching the 6th data disk will cause device name change on agent node, e.g. following lun0 disk should be &lt;code>sdc&lt;/code> other than &lt;code>sdk&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">azureuser@k8s-agentpool2-40588258-0:~$ tree /dev/disk/azure
...
â””â”€â”€ scsi1
â”œâ”€â”€ lun0 -&amp;gt; ../../../sdk
â”œâ”€â”€ lun1 -&amp;gt; ../../../sdj
â”œâ”€â”€ lun2 -&amp;gt; ../../../sde
â”œâ”€â”€ lun3 -&amp;gt; ../../../sdf
â”œâ”€â”€ lun4 -&amp;gt; ../../../sdg
â”œâ”€â”€ lun5 -&amp;gt; ../../../sdh
â””â”€â”€ lun6 -&amp;gt; ../../../sdi
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/60344">device name change due to azure disk host cache setting&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/57444">unable to use azure disk in StatefulSet since /dev/sd* changed after detach/attach disk&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/201">Disk error when pods are mounting a certain amount of volumes on a node&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/acs-engine/issues/1918">unable to use azure disk in StatefulSet since /dev/sd* changed after detach/attach disk&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/297">Input/output error when accessing PV&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/ACS/issues/113">PersistentVolumeClaims changing to Read-only file system suddenly&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Workaround&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>add &lt;code>cachingmode: None&lt;/code> in azure disk storage class(default is &lt;code>ReadWrite&lt;/code>), e.g.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">kind&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>StorageClass&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>apiVersion&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>storage.k8s.io/v1&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>metadata&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>name&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>hdd&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>provisioner&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kubernetes.io/azure-disk&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>parameters&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>skuname&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>Standard_LRS&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kind&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>Managed&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>cachingmode&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>None&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/60346">fix device name change issue for azure disk&lt;/a> could fix this issue too, it will change default &lt;code>cachingmode&lt;/code> value from &lt;code>ReadWrite&lt;/code> to &lt;code>None&lt;/code>.&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.6&lt;/td>
&lt;td>no such issue as &lt;code>cachingmode&lt;/code> is already &lt;code>None&lt;/code> by default&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>1.7.14&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.11&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="3-azure-disk-support-on-sovereign-cloud">3. Azure disk support on Sovereign Cloud&lt;/h2>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/50673">Azure disk on Sovereign Cloud&lt;/a> fixed this issue&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>1.7.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="4-time-cost-for-azure-disk-pvc-mount">4. Time cost for Azure Disk PVC mount&lt;/h2>
&lt;p>Original time cost for Azure Disk PVC mount on a standard node size(e.g. Standard_D2_V2) is around 1 minute, &lt;code>podAttachAndMountTimeout&lt;/code> is &lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.7/pkg/kubelet/volumemanager/volume_manager.go#L76">2 minutes&lt;/a>, total &lt;code>waitForAttachTimeout&lt;/code> is &lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.7/pkg/kubelet/volumemanager/volume_manager.go#L88">10 minutes&lt;/a>, so a disk remount(detach and attach in sequential) would possibly cost more than 2min, thus may fail.&lt;/p>
&lt;blockquote>
&lt;p>Note: for some smaller VM size which has only 1 CPU core, time cost would be much bigger(e.g. &amp;gt; 10min) since container is hard to get CPU slot.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/166">&amp;lsquo;timeout expired waiting for volumes to attach/mount for pod when cluster&amp;rsquo; when node-vm-size is Standard_B1s&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/57432">using cache fix&lt;/a> fixed this issue, which could reduce the mount time cost to around 30s.&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>no fix&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="5-azure-disk-pvc-multi-attach-error-makes-disk-mount-very-slow-or-mount-failure-forever">5. Azure disk PVC &lt;code>Multi-Attach error&lt;/code>, makes disk mount very slow or mount failure forever&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>When schedule a pod with azure disk volume from one node to another, total time cost of detach &amp;amp; attach is around 1 min from v1.9.2, while in v1.9.x, there is an &lt;a href="https://github.com/kubernetes/kubernetes/issues/62282">UnmountDevice failure issue in containerized kubelet&lt;/a> which makes disk mount very slow or mount failure forever, this issue only exists in v1.9.x due to PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/51771">Refactor nsenter&lt;/a>, v1.10.0 won't have this issue since &lt;code>devicePath&lt;/code> is updated in &lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.10/pkg/volume/util/operationexecutor/operation_generator.go#L1130-L1131">v1.10 code&lt;/a>&lt;/p>
&lt;p>&lt;strong>error logs&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>kubectl describe po POD-NAME&lt;/code>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">Events:
Type Reason Age From Message
---- ------ ---- ---- -------
Normal Scheduled 3m default-scheduler Successfully assigned deployment-azuredisk1-6cd8bc7945-kbkvz to k8s-agentpool-88970029-0
Warning FailedAttachVolume 3m attachdetach-controller Multi-Attach error &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> volume &lt;span style="color:#4e9a06">&amp;#34;pvc-6f2d0788-3b0b-11e8-a378-000d3afe2762&amp;#34;&lt;/span> Volume is already exclusively attached to one node and can&lt;span style="color:#a40000">&amp;#39;&lt;/span>t be attached to another
Normal SuccessfulMountVolume 3m kubelet, k8s-agentpool-88970029-0 MountVolume.SetUp succeeded &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> volume &lt;span style="color:#4e9a06">&amp;#34;default-token-qt7h6&amp;#34;&lt;/span>
Warning FailedMount 1m kubelet, k8s-agentpool-88970029-0 Unable to mount volumes &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> pod &lt;span style="color:#4e9a06">&amp;#34;deployment-azuredisk1-6cd8bc7945-kbkvz_default(5346c040-3e4c-11e8-a378-000d3afe2762)&amp;#34;&lt;/span>: timeout expired waiting &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> volumes to attach/mount &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> pod &lt;span style="color:#4e9a06">&amp;#34;default&amp;#34;&lt;/span>/&lt;span style="color:#4e9a06">&amp;#34;deployment-azuredisk1-6cd8bc7945-kbkvz&amp;#34;&lt;/span>. list of unattached/unmounted &lt;span style="color:#000">volumes&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>azuredisk&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>kubelet logs from the new node&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">E0412 20:08:10.920284 &lt;span style="color:#0000cf;font-weight:bold">7602&lt;/span> nestedpendingoperations.go:263&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Operation &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;\&amp;#34;kubernetes.io/azure-disk//subscriptions/xxx/resourceGroups/MC_xxx_eastus/providers/Microsoft.Compute/disks/kubernetes-dynamic-pvc-11035a31-3e8d-11e8-82ec-0a58ac1f04cf\&amp;#34;&amp;#34;&lt;/span> failed. No retries permitted &lt;span style="color:#204a87;font-weight:bold">until&lt;/span> 2018-04-12 20:08:12.920234762 +0000 UTC &lt;span style="color:#000">m&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>+1467.278612421 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>durationBeforeRetry 2s&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>. Error: &lt;span style="color:#4e9a06">&amp;#34;Volume has not been added to the list of VolumesInUse in the node&amp;#39;s volume status for volume \&amp;#34;pvc-11035a31-3e8d-11e8-82ec-0a58ac1f04cf\&amp;#34; (UniqueName: \&amp;#34;kubernetes.io/azure-disk//subscriptions/xxx/resourceGroups/MC_xxx_eastus/providers/Microsoft.Compute/disks/kubernetes-dynamic-pvc-11035a31-3e8d-11e8-82ec-0a58ac1f04cf\&amp;#34;) pod \&amp;#34;symbiont-node-consul-0\&amp;#34; (UID: \&amp;#34;11043b12-3e8d-11e8-82ec-0a58ac1f04cf\&amp;#34;) &amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/62282">UnmountDevice would fail in containerized kubelet&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/acs-engine/issues/2022">upgrade k8s process is broke&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Mitigation&lt;/strong>:&lt;/p>
&lt;p>If azure disk PVC mount successfully in the end, there is no action, while if it could not be mounted for more than 20min, following actions could be taken:&lt;/p>
&lt;ul>
&lt;li>check whether &lt;code>volumesInUse&lt;/code> list has unmounted azure disks, run:&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>kubectl get no NODE-NAME -o yaml &amp;gt; node.log
&lt;/code>&lt;/pre>&lt;p>all volumes in &lt;code>volumesInUse&lt;/code> should be also in &lt;code>volumesAttached&lt;/code>, otherwise there would be issue&lt;/p>
&lt;ul>
&lt;li>restart kubelet on the original node would solve this issue: &lt;code>sudo kubectl kubelet restart&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/62467">fix nsenter GetFileType issue in containerized kubelet&lt;/a> fixed this issue&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>v1.9.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>After fix in v1.9.7, it took about 1 minute for scheduling one azure disk mount from one node to another, you could find details &lt;a href="https://github.com/kubernetes/kubernetes/issues/62282#issuecomment-380794459">here&lt;/a>.&lt;/p>
&lt;p>Since azure disk attach/detach operation on a VM cannot be parallel, scheduling 3 azure disk mounts from one node to another would cost about 3 minutes.&lt;/p>
&lt;h2 id="6-waitforattach-failed-for-azure-disk-parsing-devdiskazurescsi1lun1-invalid-syntax">6. WaitForAttach failed for azure disk: parsing &amp;ldquo;/dev/disk/azure/scsi1/lun1&amp;rdquo;: invalid syntax&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:
MountVolume.WaitForAttach may fail in the azure disk remount&lt;/p>
&lt;p>&lt;strong>error logs&lt;/strong>:&lt;/p>
&lt;p>in v1.10.0 &amp;amp; v1.10.1, &lt;code>MountVolume.WaitForAttach&lt;/code> will fail in the azure disk remount, error logs would be like following:&lt;/p>
&lt;ul>
&lt;li>incorrect &lt;code>DevicePath&lt;/code> format on Linux&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>MountVolume.WaitForAttach failed for volume &amp;quot;pvc-f1562ecb-3e5f-11e8-ab6b-000d3af9f967&amp;quot; : azureDisk - Wait for attach expect device path as a lun number, instead got: /dev/disk/azure/scsi1/lun1 (strconv.Atoi: parsing &amp;quot;/dev/disk/azure/scsi1/lun1&amp;quot;: invalid syntax)
Warning FailedMount 1m (x10 over 21m) kubelet, k8s-agentpool-66825246-0 Unable to mount volumes for pod
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>wrong &lt;code>DevicePath&lt;/code>(LUN) number on Windows&lt;/li>
&lt;/ul>
&lt;pre>&lt;code> Warning FailedMount 1m kubelet, 15282k8s9010 MountVolume.WaitForAttach failed for volume &amp;quot;disk01&amp;quot; : azureDisk - WaitForAttach failed within timeout node (15282k8s9010) diskId:(andy-mghyb
1102-dynamic-pvc-6c526c51-4a18-11e8-ab5c-000d3af7b38e) lun:(4)
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/62540">WaitForAttach failed for azure disk: parsing &amp;ldquo;/dev/disk/azure/scsi1/lun1&amp;rdquo;: invalid syntax&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/acs-engine/issues/2906">Pod unable to attach PV after being deleted (Wait for attach expect device path as a lun number, instead got: /dev/disk/azure/scsi1/lun0 (strconv.Atoi: parsing &amp;ldquo;/dev/disk/azure/scsi1/lun0&amp;rdquo;: invalid syntax)&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/62612">fix WaitForAttach failure issue for azure disk&lt;/a> fixed this issue&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.2&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="7-uid-and-gid-setting-in-azure-disk">7. &lt;code>uid&lt;/code> and &lt;code>gid&lt;/code> setting in azure disk&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:
Unlike azure file mountOptions, you will get following failure if set &lt;code>mountOptions&lt;/code> like &lt;code>uid=999,gid=999&lt;/code> in azure disk mount:&lt;/p>
&lt;pre>&lt;code>azureDisk - mountDevice:FormatAndMount failed with exit status 32
&lt;/code>&lt;/pre>&lt;p>That's because azureDisk use ext4 file system by default, mountOptions like [uid=x,gid=x] could not be set in mount time.&lt;/p>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/67014">Timeout expired waiting for volumes to attach&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Solution&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>option#1: Set uid in &lt;code>runAsUser&lt;/code> and gid in &lt;code>fsGroup&lt;/code> for pod: &lt;a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/">security context for a Pod&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>e.g. Following setting will set pod run as root, make it accessible to any file:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">apiVersion&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>v1&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>kind&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>Pod&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>metadata&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>name&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>security-context-demo&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>spec&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>securityContext&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>runAsUser&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>fsGroup&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>Note: Since gid &amp;amp; uid is mounted as 0(root) by default, if set as non-root(e.g. 1000), k8s will use chown to change all dir/files under that disk, this is a time consuming job, which would make mount device very slow, in this issue: &lt;a href="https://github.com/kubernetes/kubernetes/issues/67014#issuecomment-413546283">Timeout expired waiting for volumes to attach&lt;/a>, it costs about 10 min for chown operation complete.&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>option#2: use &lt;code>chown&lt;/code> in &lt;code>initContainers&lt;/code>&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>initContainers:
- name: volume-mount
image: busybox
command: [&amp;quot;sh&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;chown -R 100:100 /data&amp;quot;]
volumeMounts:
- name: &amp;lt;your data volume&amp;gt;
mountPath: /data
&lt;/code>&lt;/pre>&lt;h2 id="8-addition-of-a-blob-based-disk-to-vm-with-managed-disks-is-not-supported">8. &lt;code>Addition of a blob based disk to VM with managed disks is not supported&lt;/code>&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>Following error may occur if attach a blob based(unmanaged) disk to VM with managed disks:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh"> Warning FailedMount 42s &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>x2 over 1m&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> attachdetach AttachVolume.Attach failed &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> volume &lt;span style="color:#4e9a06">&amp;#34;pvc-f17e5e77-474e-11e8-a2ea-000d3a10df6d&amp;#34;&lt;/span> : Attach volume &lt;span style="color:#4e9a06">&amp;#34;holo-k8s-dev-dynamic-pvc-f17e5e77-474e-11e8-a2ea-000d3a10df6d&amp;#34;&lt;/span> to instance &lt;span style="color:#4e9a06">&amp;#34;k8s-master-92699158-0&amp;#34;&lt;/span> failed with compute.VirtualMachinesClient#CreateOrUpdate: Failure responding to request: &lt;span style="color:#000">StatusCode&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">409&lt;/span> -- Original Error: autorest/azure: Service returned an error. &lt;span style="color:#000">Status&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">409&lt;/span> &lt;span style="color:#000">Code&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;OperationNotAllowed&amp;#34;&lt;/span> &lt;span style="color:#000">Message&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;Addition of a blob based disk to VM with managed disks is not supported.&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This issue is by design as in Azure, there are two kinds of disks, blob based(unmanaged) disk and managed disk, an Azure VM could not attach both of these two kinds of disks.&lt;/p>
&lt;p>&lt;strong>Solution&lt;/strong>:&lt;/p>
&lt;p>Use &lt;code>default&lt;/code> azure disk storage class in aks-engine, as &lt;code>default&lt;/code> will always be identical to the agent pool, that is, if VM is managed, it will be managed azure disk class, if unmanaged, then it's unmanaged disk class.&lt;/p>
&lt;h2 id="9-dynamic-azure-disk-pvc-try-to-access-wrong-storage-account-of-other-resource-group">9. dynamic azure disk PVC try to access wrong storage account (of other resource group)&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>In a k8s cluster with &lt;strong>blob based&lt;/strong> VMs(won't happen in AKS since AKS only use managed disk), create dynamic azure disk PVC may fail, error logs is like following:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">Failed to provision volume with StorageClass &lt;span style="color:#4e9a06">&amp;#34;default&amp;#34;&lt;/span>: azureDisk - account ds6c822a4d484211eXXXXXX does not exist &lt;span style="color:#204a87;font-weight:bold">while&lt;/span> trying to create/ensure default container
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Azure/acs-engine/issues/2768">Multiple clusters - dynamic PVCs try to access wrong storage account (of other resource group)&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/56474">fix storage account not found issue: use ListByResourceGroup instead of List()&lt;/a> fixed this issue&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.13&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>this bug only exists in blob based VM in v1.8.x, v1.9.x, so if specify &lt;code>ManagedDisks&lt;/code> when creating k8s cluster in aks-engine(AKS is using managed disk by default), it won't have this issue:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json"> &lt;span style="color:#4e9a06">&amp;#34;agentPoolProfiles&amp;#34;&lt;/span>&lt;span style="color:#a40000">:&lt;/span> &lt;span style="color:#000;font-weight:bold">[&lt;/span>
&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#a40000">.&lt;/span>&lt;span style="color:#a40000">.&lt;/span>&lt;span style="color:#a40000">.&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;storageProfile&amp;#34;&lt;/span> &lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;ManagedDisks&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#a40000">.&lt;/span>&lt;span style="color:#a40000">.&lt;/span>&lt;span style="color:#a40000">.&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="10-data-loss-if-using-existing-azure-disk-with-partitions-in-disk-mount">10. data loss if using existing azure disk with partitions in disk mount&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>When use an existing azure disk(also called &lt;a href="https://github.com/andyzhangx/demo/tree/master/linux/azuredisk#static-provisioning-for-azure-disk">static provisioning&lt;/a>) in pod, if that disk has partitions, the disk will be formatted in the pod mounting process, actually k8s volume don't support mount disk with partitions, disk mount would fail finally. While for mounting existing &lt;strong>azure&lt;/strong> disk that has partitions, data will be lost since it will format that disk first. This issue happens only on &lt;strong>Linux&lt;/strong>.&lt;/p>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/63235">data loss if using existing azure disk with partitions in disk mount&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/63270">fix data loss issue if using existing azure disk with partitions in disk mount&lt;/a> will let azure provider return error when mounting existing azure disk that has partitions&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.15&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.11&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>1.11.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>Don't use existing azure disk that has partitions, e.g. following disk in LUN 0 that has one partition:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">azureuser@aks-nodepool1-28371372-0:/$ ls -l /dev/disk/azure/scsi1/
total &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
lrwxrwxrwx &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> root root &lt;span style="color:#0000cf;font-weight:bold">12&lt;/span> Apr &lt;span style="color:#0000cf;font-weight:bold">27&lt;/span> 08:04 lun0 -&amp;gt; ../../../sdc
lrwxrwxrwx &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> root root &lt;span style="color:#0000cf;font-weight:bold">13&lt;/span> Apr &lt;span style="color:#0000cf;font-weight:bold">27&lt;/span> 08:04 lun0-part1 -&amp;gt; ../../../sdc1
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="11-delete-azure-disk-pvc-which-is-already-in-use-by-a-pod">11. Delete azure disk PVC which is already in use by a pod&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>Following error may occur if delete azure disk PVC which is already in use by a pod:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">kubectl describe pv pvc-d8eebc1d-74d3-11e8-902b-e22b71bb1c06
...
Message: disk.DisksClient#Delete: Failure responding to request: &lt;span style="color:#000">StatusCode&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">409&lt;/span> -- Original Error: autorest/azure: Service returned an error. &lt;span style="color:#000">Status&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">409&lt;/span> &lt;span style="color:#000">Code&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;OperationNotAllowed&amp;#34;&lt;/span> &lt;span style="color:#000">Message&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;Disk kubernetes-dynamic-pvc-d8eebc1d-74d3-11e8-902b-e22b71bb1c06 is attached to VM /subscriptions/{subs-id}/resourceGroups/MC_markito-aks-pvc_markito-aks-pvc_westus/providers/Microsoft.Compute/virtualMachines/aks-agentpool-25259074-0.&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Fix&lt;/strong>:&lt;/p>
&lt;p>This is a common k8s issue, other cloud provider would also has this issue. There is a &lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/pvc-protection/">PVC protection&lt;/a> feature to prevent this, it's alpha in v1.9, and beta(enabled by default) in v1.10&lt;/p>
&lt;p>&lt;strong>Work around&lt;/strong>:
delete pod first and then delete azure disk pvc after a few minutes&lt;/p>
&lt;h2 id="12-create-azure-disk-pvc-failed-due-to-account-creation-failure">12. create azure disk PVC failed due to account creation failure&lt;/h2>
&lt;blockquote>
&lt;p>please note this issue only happens on &lt;strong>unmanaged&lt;/strong> k8s cluster&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>Issue details&lt;/strong>: User may get &lt;code>Account property kind is invalid for the request&lt;/code> error when trying to create a new &lt;strong>unmanaged&lt;/strong> azure disk PVC, error would be like following:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">azureuser@k8s-master-17140924-0:/tmp$ kubectl describe pvc
Name: pvc-azuredisk
Namespace: default
StorageClass: hdd
Status: Bound
...
Events:
Type Reason Age From Message
---- ------ ---- ---- -------
Warning ProvisioningFailed 31m persistentvolume-controller Failed to provision volume with StorageClass &lt;span style="color:#4e9a06">&amp;#34;hdd&amp;#34;&lt;/span>: Create Storage Account: ds10e15ed89c5811e8a0a70, error: storage.AccountsClient#Create: Failure sending request: &lt;span style="color:#000">StatusCode&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">400&lt;/span> -- Original Error: &lt;span style="color:#000">Code&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;AccountPropertyIsInvalid&amp;#34;&lt;/span> &lt;span style="color:#000">Message&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;Account property kind is invalid for the request.&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/67236">fix azure disk create failure due to sdk upgrade&lt;/a> fixed this issue&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>1.11.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>create a storage account and specify that account in azure disk storage class, e.g.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">kind&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>StorageClass&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>apiVersion&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>storage.k8s.io/v1beta1&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>metadata&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>name&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>ssd&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>provisioner&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kubernetes.io/azure-disk&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>parameters&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>skuname&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>Premium_LRS&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>storageAccount&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>customerstorageaccount&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>kind&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>Dedicated&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="13-cannot-find-lun-for-disk">13. cannot find Lun for disk&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>Following error may occur if attach a disk to a node:&lt;/p>
&lt;pre>&lt;code>MountVolume.WaitForAttach failed for volume &amp;quot;pvc-12b458f4-c23f-11e8-8d27-46799c22b7c6&amp;quot; : Cannot find Lun for disk kubernetes-dynamic-pvc-12b458f4-c23f-11e8-8d27-46799c22b7c6
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/69262">GetAzureDiskLun sometimes costs 1 min which is too long time&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/70002">fix azure disk attachment error on Linux&lt;/a> will extract the LUN num from device path &lt;strong>only on Linux&lt;/strong>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.10&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>1.11.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>1.12.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>wait for a few more minutes should work&lt;/p>
&lt;h2 id="14-azure-disk-attachdetach-failure-mount-issue-io-error">14. azure disk attach/detach failure, mount issue, i/o error&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>We found a disk attach/detach issue due to &lt;a href="https://github.com/kubernetes/kubernetes/pull/58313">dirty vm cache PR&lt;/a> introduced from v1.9.2, it would lead to following disk issues:&lt;/p>
&lt;ul>
&lt;li>disk attach/detach failure for a long time&lt;/li>
&lt;li>disk I/O error&lt;/li>
&lt;li>unexpected disk detachment from VM&lt;/li>
&lt;li>VM running into failed state due to attaching non-existing disk&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>Note: above error may &lt;strong>only&lt;/strong> happen when there are multiple disk attach/detach operations in parallel and it's not easy to repro since it happens on a little possibility.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/71344">Azure Disks volume attach still times out on Kubernetes 1.10&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/71453">Azure Disks occasionally mounted in a way leading to I/O errors&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;p>We changed the azure disk attach/detach retry logic in k8s v1.13, switch to use k8s attach-detach controller to do attach/detach disk retry and clean vm cache after every disk operation, this issue is proved to be fixed in our disk attach/detach stress test and also verified in customer env:&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/70568">remove retry operation on attach/detach azure disk in azure cloud provider&lt;/a>&lt;/li>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/71377">fix azure disk attach/detach failed forever issue&lt;/a>&lt;/li>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/71495">fix detach azure disk issue due to dirty cache&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>issue introduced in v1.9.2, no cherry-pick fix allowed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.12&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>1.11.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>1.12.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>if there is attach disk failure for long time, restart controller manager may work&lt;/li>
&lt;li>if there is disk not detached for long time, detach that disk manually&lt;/li>
&lt;/ul></description></item><item><title>Docs: Azure File Plugin Known Issues</title><link>https://nilo19.github.io/cloud-provider-azure/docs/persistentvolumes/azurefile/issues/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/docs/persistentvolumes/azurefile/issues/</guid><description>
&lt;!-- TOC -->
&lt;ul>
&lt;li>&lt;a href="#azure-file-plugin-known-issues">azure file plugin known issues&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#recommended-stable-version-for-azure-file">Recommended stable version for azure file&lt;/a>&lt;/li>
&lt;li>&lt;a href="#1-azure-file-mountoptions-setting">1. azure file mountOptions setting&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#filedir-mode-setting">file/dir mode setting:&lt;/a>&lt;/li>
&lt;li>&lt;a href="#other-useful-mountoptions-setting">other useful &lt;code>mountOptions&lt;/code> setting:&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#2-permission-issue-of-azure-file-dynamic-provision-in-aks-engine">2. permission issue of azure file dynamic provision in aks-engine&lt;/a>&lt;/li>
&lt;li>&lt;a href="#3-azure-file-support-on-sovereign-cloud">3. Azure file support on Sovereign Cloud&lt;/a>&lt;/li>
&lt;li>&lt;a href="#4-azure-file-dynamic-provision-failed-due-to-cluster-name-length-issue">4. azure file dynamic provision failed due to cluster name length issue&lt;/a>&lt;/li>
&lt;li>&lt;a href="#5-azure-file-dynamic-provision-failed-due-to-no-storage-account-in-current-resource-group">5. azure file dynamic provision failed due to no storage account in current resource group&lt;/a>&lt;/li>
&lt;li>&lt;a href="#6-azure-file-plugin-on-windows-does-not-work-after-node-restart">6. azure file plugin on Windows does not work after node restart&lt;/a>&lt;/li>
&lt;li>&lt;a href="#7-file-permission-could-not-be-changed-using-azure-file-eg-postgresql">7. file permission could not be changed using azure file, e.g. postgresql&lt;/a>&lt;/li>
&lt;li>&lt;a href="#8-could-not-delete-pod-with-azurefile-volume-if-storage-account-key-changed">8. Could not delete pod with AzureFile volume if storage account key changed&lt;/a>&lt;/li>
&lt;li>&lt;a href="#9-long-latency-compared-to-disk-when-handling-lots-of-small-files">9. Long latency when handling lots of small files&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;!-- /TOC -->
&lt;h2 id="recommended-stable-version-for-azure-file">Recommended stable version for azure file&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>stable version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>1.7.14 or later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.11 or later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.7 or later&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.2 or later&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="1-azure-file-mountoptions-setting">1. azure file mountOptions setting&lt;/h2>
&lt;h3 id="filedir-mode-setting">file/dir mode setting:&lt;/h3>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>fileMode&lt;/code>, &lt;code>dirMode&lt;/code> value would be different in different versions, in latest master branch, it's &lt;code>0755&lt;/code> by default, to set a different value, follow this &lt;a href="https://github.com/andyzhangx/Demo/blob/master/linux/azurefile/azurefile-mountoptions.md">mount options support of azure file&lt;/a> (available from v1.8.5).&lt;/li>
&lt;li>For version v1.8.0-v1.8.4, since &lt;a href="https://github.com/andyzhangx/Demo/blob/master/linux/azurefile/azurefile-mountoptions.md">mount options support of azure file&lt;/a> is not available, as a workaround, &lt;a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/">securityContext&lt;/a> could be specified for the pod, &lt;a href="https://github.com/andyzhangx/Demo/blob/master/linux/azurefile/demo-azurefile-securitycontext.yaml">detailed pod example&lt;/a>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>securityContext&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>runAsUser&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>XXX&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>fsGroup&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>XXX&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>version&lt;/th>
&lt;th>&lt;code>fileMode&lt;/code>, &lt;code>dirMode&lt;/code> value&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.6.x, v1.7.x&lt;/td>
&lt;td>0777&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8.0 ~ v1.8.5, v1.9.0&lt;/td>
&lt;td>0700&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8.6 or later, v1.9.1 ~ v1.10.9, v1.11.0 ~ v1.11.3, v1.12.0 ~ v.12.1&lt;/td>
&lt;td>0755&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10.10 or later&lt;/td>
&lt;td>0777&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11.4 or later&lt;/td>
&lt;td>0777&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12.2 or later&lt;/td>
&lt;td>0777&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13.x&lt;/td>
&lt;td>0777&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="other-useful-mountoptions-setting">other useful &lt;code>mountOptions&lt;/code> setting:&lt;/h3>
&lt;ul>
&lt;li>&lt;code>mfsymlinks&lt;/code>: make azure file(cifs) mount supports symbolic link&lt;/li>
&lt;li>&lt;code>nobrl&lt;/code>: Do not send byte range lock requests to the server. This is necessary for certain applications that break with cifs style mandatory byte range locks (and most cifs servers do not yet support requesting advisory byte range locks). Error message could be like following:&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">Error: SQLITE_BUSY: database is locked
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/54610">azureFile volume mode too strict for container with non root user&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/59755">Unable to connect to SQL-lite db mounted on AzureFile/AzureDisks [SQLITE_BUSY: database is locked]&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/61767">Allow nobrl parameter like docker to use sqlite over network drive&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/58308">Error to deploy mongo with azure file storage&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="2-permission-issue-of-azure-file-dynamic-provision-in-aks-engine">2. permission issue of azure file dynamic provision in aks-engine&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>From acs-engine v0.12.0, RBAC is enabled, azure file dynamic provision does not work from this version&lt;/p>
&lt;p>&lt;strong>error logs&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">Events:
Type Reason Age From Message
---- ------ ---- ---- -------
Warning ProvisioningFailed 8s persistentvolume-controller Failed to provision volume with StorageClass &lt;span style="color:#4e9a06">&amp;#34;azurefile&amp;#34;&lt;/span>: Couldn&lt;span style="color:#a40000">&amp;#39;&lt;/span>t create secret secrets is forbidden: User &lt;span style="color:#4e9a06">&amp;#34;system:serviceaccount:kube-syste
&lt;/span>&lt;span style="color:#4e9a06">m:persistent-volume-binder&amp;#34;&lt;/span> cannot create secrets in the namespace &lt;span style="color:#4e9a06">&amp;#34;default&amp;#34;&lt;/span>
Warning ProvisioningFailed 8s persistentvolume-controller Failed to provision volume with StorageClass &lt;span style="color:#4e9a06">&amp;#34;azurefile&amp;#34;&lt;/span>: failed to find a matching storage account
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/59543">azure file PVC need secrets create permission for persistent-volume-binder&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Workaround&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Add a ClusterRole and ClusterRoleBinding for &lt;a href="https://github.com/andyzhangx/Demo/tree/master/linux/azurefile#dynamic-provisioning-for-azure-file-in-linux-support-from-v170">azure file dynamic privision&lt;/a>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">kubectl create -f https://raw.githubusercontent.com/andyzhangx/Demo/master/acs-engine/rbac/azure-cloud-provider-deployment.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>delete the original PVC and recreate PVC&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR in acs-engine: &lt;a href="https://github.com/Azure/acs-engine/pull/2238">fix azure file dynamic provision permission issue&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="3-azure-file-support-on-sovereign-cloud">3. Azure file support on Sovereign Cloud&lt;/h2>
&lt;p>&lt;a href="https://github.com/kubernetes/kubernetes/pull/48460">Azure file on Sovereign Cloud&lt;/a> is supported from v1.7.11, v1.8.0&lt;/p>
&lt;h2 id="4-azure-file-dynamic-provision-failed-due-to-cluster-name-length-issue">4. azure file dynamic provision failed due to cluster name length issue&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:
k8s cluster name length must be less than 16 characters, otherwise following error will be received when creating dynamic privisioning azure file pvc, this bug exists in [v1.7.0, v1.7.10]:&lt;/p>
&lt;blockquote>
&lt;p>Note: check &lt;code>cluster-name&lt;/code> by running &lt;code>grep cluster-name /etc/kubernetes/manifests/kube-controller-manager.yaml&lt;/code> on master node&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">persistentvolume-controller Warning ProvisioningFailed Failed to provision volume with StorageClass &lt;span style="color:#4e9a06">&amp;#34;azurefile&amp;#34;&lt;/span>: failed to find a matching storage account
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/48326">Fix share name generation in azure file provisioner&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>1.7.11&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="5-azure-file-dynamic-provision-failed-due-to-no-storage-account-in-current-resource-group">5. azure file dynamic provision failed due to no storage account in current resource group&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>When create an azure file PVC, there will be error if there is no storage account in current resource group, error info would be like following:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">Events:
Type Reason Age From Message
---- ------ ---- ---- -------
Warning ProvisioningFailed 10s &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>x5 over 1m&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> persistentvolume-controller Failed to provision volume with StorageClass &lt;span style="color:#4e9a06">&amp;#34;azurefile-premium&amp;#34;&lt;/span>: failed to find a matching storage account
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/56556">failed to create azure file pvc if there is no storage account in current resource group&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Workaround&lt;/strong>:
specify a storage account in azure file dynamic provision, you should make sure the specified storage account is in the same resource group as your k8s cluster. In AKS, the specified storage account should be in &lt;code>shadow resource group&lt;/code>(naming as &lt;code>MC_+{RESOUCE-GROUP-NAME}+{CLUSTER-NAME}+{REGION}&lt;/code>) which contains all resources of your aks cluster.&lt;/p>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/56557">fix the create azure file pvc failure if there is no storage account in current resource group&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>1.7.14&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="6-azure-file-plugin-on-windows-does-not-work-after-node-restart">6. azure file plugin on Windows does not work after node restart&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:
azure file plugin on Windows does not work after node restart, this is due to &lt;code>New-SmbGlobalMapping&lt;/code> cmdlet has lost account name/key after reboot&lt;/p>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/60624">azure file plugin on Windows does not work after node restart&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Workaround&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>delete the original pod with azure file mount&lt;/li>
&lt;li>create the pod again&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/60625">fix azure file plugin failure issue on Windows after node restart&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>not support in upstream&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.10&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="7-file-permission-could-not-be-changed-using-azure-file-eg-postgresql">7. file permission could not be changed using azure file, e.g. postgresql&lt;/h2>
&lt;p>&lt;strong>error logs&lt;/strong> when running postgresql on azure file plugin:&lt;/p>
&lt;pre>&lt;code>initdb: could not change permissions of directory &amp;quot;/var/lib/postgresql/data&amp;quot;: Operation not permitted
fixing permissions on existing directory /var/lib/postgresql/data
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Issue details&lt;/strong>:
azure file plugin is using cifs/SMB protocol, file/dir permission could not be changed after mounting&lt;/p>
&lt;p>&lt;strong>Workaround&lt;/strong>:
Use &lt;code>subPath&lt;/code> together with azure disk plugin (for ext3/4 disk type, there is a &lt;code>lost+found&lt;/code> directory after disk format)&lt;/p>
&lt;p>&lt;strong>Related issues&lt;/strong>
&lt;a href="https://github.com/Azure/AKS/issues/225">Persistent Volume Claim permissions&lt;/a>&lt;/p>
&lt;h2 id="8-could-not-delete-pod-with-azurefile-volume-if-storage-account-key-changed">8. Could not delete pod with AzureFile volume if storage account key changed&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>kubelet fails to umount azurefile volume when there is azure file connection, below is an easy repro:
&lt;ul>
&lt;li>create a pod with azure file mount&lt;/li>
&lt;li>regenerate the account key of the storage account&lt;/li>
&lt;li>delete the pod, and the pod will never be deleted due to &lt;code>UnmountVolume.TearDown&lt;/code> error&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>error logs&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">nestedpendingoperations.go:263&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Operation &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;\&amp;#34;kubernetes.io/azure-file/cc5c86cd-422a-11e8-91d7-000d3a03ee84-myvolume\&amp;#34; (\&amp;#34;cc5c86cd-422a-11e8-91d7-000d3a03ee84\&amp;#34;)&amp;#34;&lt;/span> failed. No retries permitted &lt;span style="color:#204a87;font-weight:bold">until&lt;/span> 2018-04-17 10:35:40.240272223 +0000 UTC &lt;span style="color:#000">m&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>+1185722.391925424 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>durationBeforeRetry 500ms&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>. Error: &lt;span style="color:#4e9a06">&amp;#34;UnmountVolume.TearDown failed for volume \&amp;#34;myvolume\&amp;#34; (UniqueName: \&amp;#34;kubernetes.io/azure-file/cc5c86cd-422a-11e8-91d7-000d3a03ee84-myvolume\&amp;#34;) pod \&amp;#34;cc5c86cd-422a-11e8-91d7-000d3a03ee84\&amp;#34; (UID: \&amp;#34;cc5c86cd-422a-11e8-91d7-000d3a03ee84\&amp;#34;) : Error checking if path exists: stat /var/lib/kubelet/pods/cc5c86cd-422a-11e8-91d7-000d3a03ee84/volumes/kubernetes.io~azure-file/myvolume: resource temporarily unavailable
&lt;/span>&lt;span style="color:#4e9a06">...
&lt;/span>&lt;span style="color:#4e9a06">kubelet_volumes.go:128] Orphaned pod &amp;#34;&lt;/span>380b02f3-422b-11e8-91d7-000d3a03ee84&lt;span style="color:#4e9a06">&amp;#34;&lt;/span>&lt;span style="color:#4e9a06"> found, but volume paths are still present on disk
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Workaround&lt;/strong>:&lt;/p>
&lt;p>manually umount the azure file mount path on the agent node and then the pod will be deleted right after that&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">sudo umount /var/lib/kubelet/pods/cc5c86cd-422a-11e8-91d7-000d3a03ee84/volumes/kubernetes.io~azure-file/myvolume
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/52324">Fix bug:Kubelet failure to umount mount points&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>no fix(no cherry-pick fix is allowed)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/62824">UnmountVolume.TearDown fails for AzureFile volume, locks up node&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/41141">Kubelet failure to umount glusterfs mount points&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="9-long-latency-compared-to-disk-when-handling-lots-of-small-files">9. Long latency compared to disk when handling lots of small files&lt;/h2>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/223">&lt;code>azurefile&lt;/code> is very slow&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/helm/charts/issues/5751">Can't roll out Wordpress chart with PV on AzureFile&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Docs: Kubernetes E2E tests</title><link>https://nilo19.github.io/cloud-provider-azure/docs/e2e/e2e-tests/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nilo19.github.io/cloud-provider-azure/docs/e2e/e2e-tests/</guid><description>
&lt;h2 id="prerequisite">Prerequisite&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>An azure service principal&lt;/p>
&lt;p>Please follow this &lt;a href="https://github.com/Azure/aks-engine/blob/master/docs/topics/service-principals.md">guide&lt;/a> for creating an azure service principal
The service principal should either have:&lt;/p>
&lt;ul>
&lt;li>Contributor permission of a subscription&lt;/li>
&lt;li>Contributor permission of a resource group. In this case, please create the resource group first&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Docker daemon enabled&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="how-to-run-kubernetes-e2e-tests-locally">How to run Kubernetes e2e tests locally&lt;/h2>
&lt;ol>
&lt;li>Prepare dependency project&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/Azure/aks-engine">aks-engine&lt;/a>&lt;/p>
&lt;p>Binary downloads for the latest version of aks-engine for are available &lt;a href="https://github.com/Azure/aks-engine/releases/latest">on Github&lt;/a>. Download AKS Engine for your operating system, extract the binary and copy it to your &lt;code>$PATH&lt;/code>.&lt;/p>
&lt;p>On macOS, you can install aks-engine with &lt;a href="https://brew.sh/">Homebrew&lt;/a>. Run the command &lt;code>brew install Azure/aks-engine/aks-engine&lt;/code> to do so. You can install Homebrew following the &lt;a href="https://brew.sh/">instructions&lt;/a>.&lt;/p>
&lt;p>On Windows, you can install aks-engine via &lt;a href="https://chocolatey.org/">Chocolatey&lt;/a> by executing the command &lt;code>choco install aks-engine&lt;/code>. You can install Chocolatey following the &lt;a href="https://chocolatey.org/install">instructions&lt;/a>.&lt;/p>
&lt;p>On Linux, it could also be installed by following commands:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ curl -o get-akse.sh https://raw.githubusercontent.com/Azure/aks-engine/master/scripts/get-akse.sh
$ chmod &lt;span style="color:#0000cf;font-weight:bold">700&lt;/span> get-akse.sh
$ ./get-akse.sh
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/kubernetes/kubernetes">Kubernetes&lt;/a>&lt;/p>
&lt;p>This serves as E2E tests case source, it should be located at &lt;code>$GOPATH/src/k8s.io/kubernetes&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#204a87">cd&lt;/span> &lt;span style="color:#000">$GOPATH&lt;/span>/src
go get -d k8s.io/kubernetes
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://kubectl.docs.kubernetes.io/">kubectl&lt;/a>&lt;/p>
&lt;p>Kubectl allows you to run command against Kubernetes cluster, which is also used for deploying CSI plugins. You can follow &lt;a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-binary-with-curl">here&lt;/a> to install kubectl. e.g. on Linux&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">curl -LO https://storage.googleapis.com/kubernetes-release/release/&lt;span style="color:#204a87;font-weight:bold">$(&lt;/span>curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt&lt;span style="color:#204a87;font-weight:bold">)&lt;/span>/bin/linux/amd64/kubectl
chmod +x kubectl
sudo mv kubectl /usr/local/bin/
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>
&lt;p>Build docker image &lt;code>azure-cloud-controller-manager&lt;/code> and push it to your docker image repository.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">git clone https://github.com/kubernetes-sigs/cloud-provider-azure &lt;span style="color:#000">$GOPATH&lt;/span>/src/sigs.k8s.io/cloud-provider-azure
&lt;span style="color:#204a87">cd&lt;/span> &lt;span style="color:#000">$GOPATH&lt;/span>/src/sigs.k8s.io/cloud-provider-azure
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">IMAGE_REGISTRY&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;username&amp;gt;
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">IMAGE_TAG&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;tag&amp;gt;
make build-images
make push-images &lt;span style="color:#8f5902;font-style:italic"># or manually `docker push`&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Deploy a Kubernetes cluster with the above &lt;code>azure-cloud-controller-manager&lt;/code> image.&lt;/p>
&lt;p>To deploy a cluster, export all the required environmental variables first and then invoke &lt;code>make deploy&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">RESOURCE_GROUP_NAME&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;resource group name&amp;gt;
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">K8S_AZURE_LOCATION&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;location&amp;gt;
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">K8S_AZURE_SUBSID&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;subscription ID&amp;gt;
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">K8S_AZURE_SPID&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;client id&amp;gt;
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">K8S_AZURE_SPSEC&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;client secret&amp;gt;
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">K8S_AZURE_TENANTID&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;tenant id&amp;gt;
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">USE_CSI_DEFAULT_STORAGECLASS&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;true/false&amp;gt;
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">K8S_RELEASE_VERSION&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;k8s release version&amp;gt;
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">CCM_IMAGE&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;image of the cloud controller manager&amp;gt;
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">CNM_IMAGE&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&amp;lt;image of the cloud node manager&amp;gt;
make deploy
&lt;/code>&lt;/pre>&lt;/div>&lt;p>To connect the cluster:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">KUBECONFIG&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#000">$GOPATH&lt;/span>/src/sigs.k8s.io/cloud-provider-azure/_output/&lt;span style="color:#204a87;font-weight:bold">$(&lt;/span>ls -t _output &lt;span style="color:#000;font-weight:bold">|&lt;/span> head -n 1&lt;span style="color:#204a87;font-weight:bold">)&lt;/span>/kubeconfig/kubeconfig.&lt;span style="color:#000">$LOCATION&lt;/span>.json
kubectl cluster-info
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;p>To check out more of the deployed cluster , replace &lt;code>kubectl cluster-info&lt;/code> with other &lt;code>kubectl&lt;/code> commands. To further debug and diagnose cluster problems, use &lt;code>kubectl cluster-info dump&lt;/code>&lt;/p>
&lt;ol start="4">
&lt;li>Get kubetest binary&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">go get -u k8s.io/test-infra/kubetest
&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="5">
&lt;li>Run E2E tests&lt;/li>
&lt;/ol>
&lt;p>Please first ensure the kubernetes project locates at &lt;code>$GOPATH/src/k8s.io/kubernetes&lt;/code>, the e2e tests will be built from that location.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#204a87">cd&lt;/span> &lt;span style="color:#000">$GOPATH&lt;/span>/src/k8s.io/kubernetes
make &lt;span style="color:#000">WHAT&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;test/e2e/e2e.test&amp;#39;&lt;/span>
make &lt;span style="color:#000">WHAT&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>cmd/kubectl
make ginkgo
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">KUBERNETES_PROVIDER&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>azure
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">KUBERNETES_CONFORMANCE_TEST&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>y
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">KUBERNETES_CONFORMANCE_PROVIDER&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>azure
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">CLOUD_CONFIG&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#000">$GOPATH&lt;/span>/src/sigs.k8s.io/cloud-provider-azure/tests/k8s-azure/manifest/azure.json
&lt;span style="color:#8f5902;font-style:italic"># some test cases require ssh configurations&lt;/span>
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">KUBE_SSH_KEY_PATH&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>path/to/ssh/privatekey
&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">KUBE_SSH_USER&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">{&lt;/span>ssh_user&lt;span style="color:#ce5c00;font-weight:bold">}&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># Replace the test_args with your own.&lt;/span>
kubetest --test --provider&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87">local&lt;/span> --check-version-skew&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87">false&lt;/span> --test_args&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;--ginkgo.focus=Port\sforwarding&amp;#39;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div></description></item></channel></rss>